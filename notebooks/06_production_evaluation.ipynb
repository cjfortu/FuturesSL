{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULftS6aiTdxA"
      },
      "source": [
        "# Production Model Evaluation\n",
        "\n",
        "Comprehensive evaluation of trained MIGT-TVDT model from Phase 5 outputs.\n",
        "\n",
        "**Evaluation Components:**\n",
        "1. Model loading and inference on full test set\n",
        "2. Distributional metrics (CRPS, calibration, PICP, MPIW)\n",
        "3. Point prediction metrics (IC, DA, RMSE)\n",
        "4. Financial metrics (Sharpe, Sortino, MDD, profit factor)\n",
        "5. Calibration analysis and visualization\n",
        "6. Multi-horizon backtesting\n",
        "7. Comprehensive evaluation report\n",
        "\n",
        "**Outputs:** All results saved to `/content/drive/MyDrive/Colab Notebooks/Transformers/FP/evaluation_results`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IFKxQAwTdxD"
      },
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBE80XeuTdxE",
        "outputId": "0c132812-c92e-4be8-fc2c-8acaaa7b2aaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Base directory: /content/drive/MyDrive/Colab Notebooks/Transformers/FP\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "BASE_DIR = Path('/content/drive/MyDrive/Colab Notebooks/Transformers/FP')\n",
        "sys.path.insert(0, str(BASE_DIR / 'src'))\n",
        "\n",
        "print(f'Base directory: {BASE_DIR}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iGly_2SHTdxG"
      },
      "outputs": [],
      "source": [
        "!pip install -q scipy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qASAokHsTdxG",
        "outputId": "3ca68ba1-b21c-44d3-d6ea-28d860697206"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "GPU: NVIDIA A100-SXM4-80GB\n",
            "VRAM: 85.2 GB\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {device}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
        "    print(f'VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDhgM8_KTdxH"
      },
      "source": [
        "## 2. Configure Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36vF2kWYTdxH",
        "outputId": "5444b246-523b-45d1-870d-e573627c0aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paths:\n",
            "  checkpoint: exists\n",
            "  training_history: exists\n",
            "  processed_data: exists\n",
            "  results_dir: exists\n"
          ]
        }
      ],
      "source": [
        "paths = {\n",
        "    'checkpoint': BASE_DIR / 'outputs' / 'checkpoint_best.pt',\n",
        "    'training_history': BASE_DIR / 'outputs' / 'training_history.json',\n",
        "    'processed_data': BASE_DIR / 'data' / 'processed',\n",
        "    'results_dir': BASE_DIR / 'evaluation_results'\n",
        "}\n",
        "\n",
        "paths['results_dir'].mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Paths:\")\n",
        "for key, path in paths.items():\n",
        "    status = \"exists\" if path.exists() else \"missing\"\n",
        "    print(f\"  {key}: {status}\")\n",
        "\n",
        "if not paths['checkpoint'].exists():\n",
        "    raise FileNotFoundError(f\"Checkpoint not found: {paths['checkpoint']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zodpOkuTdxI"
      },
      "source": [
        "## 3. Load Training History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgsM6QeTTdxJ",
        "outputId": "5e8f919a-d215-42ee-d85e-1a81271423d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training History:\n",
            "  Epochs: 4\n",
            "  Best epoch: 3\n",
            "  Best val loss: 0.014659\n",
            "  Final train loss: 0.013142\n",
            "  Final val loss: 0.017043\n"
          ]
        }
      ],
      "source": [
        "with open(paths['training_history'], 'r') as f:\n",
        "    history = json.load(f)\n",
        "\n",
        "print(\"Training History:\")\n",
        "print(f\"  Epochs: {len(history['train_loss'])}\")\n",
        "print(f\"  Best epoch: {np.argmin(history['val_loss']) + 1}\")\n",
        "print(f\"  Best val loss: {np.min(history['val_loss']):.6f}\")\n",
        "print(f\"  Final train loss: {history['train_loss'][-1]:.6f}\")\n",
        "print(f\"  Final val loss: {history['val_loss'][-1]:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPgPnxHBTdxL"
      },
      "source": [
        "## 4. Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHQvt4UlTdxM",
        "outputId": "99bf4991-14c8-4f30-e1bd-684e765e4e5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint: epoch 2, val_loss 0.014659\n",
            "\n",
            "Model config:\n",
            "  n_variables: 24\n",
            "  max_seq_len: 288\n",
            "  n_horizons: 5\n",
            "  n_quantiles: 7\n",
            "  d_model: 256\n",
            "\n",
            "Parameters: 6,866,984\n"
          ]
        }
      ],
      "source": [
        "from model.migt_tvdt import MIGT_TVDT\n",
        "\n",
        "checkpoint = torch.load(paths['checkpoint'], map_location=device)\n",
        "\n",
        "print(f\"Checkpoint: epoch {checkpoint['epoch']}, val_loss {checkpoint['val_loss']:.6f}\")\n",
        "\n",
        "model_config = checkpoint['config']['model']\n",
        "print(f\"\\nModel config:\")\n",
        "print(f\"  n_variables: {model_config['n_variables']}\")\n",
        "print(f\"  max_seq_len: {model_config['max_seq_len']}\")\n",
        "print(f\"  n_horizons: {model_config['n_horizons']}\")\n",
        "print(f\"  n_quantiles: {model_config['n_quantiles']}\")\n",
        "print(f\"  d_model: {model_config['d_model']}\")\n",
        "\n",
        "model = MIGT_TVDT(model_config)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "n_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"\\nParameters: {n_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txW0sWzhTdxM"
      },
      "source": [
        "## 5. Extract Config Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es2pOpnOTdxN",
        "outputId": "ed4f0b7e-12b0-45b2-f34c-0f5e8e986ce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantiles: [0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95]\n",
            "Horizons: ['15m', '30m', '60m', '2h', '4h']\n"
          ]
        }
      ],
      "source": [
        "# Quantiles from checkpoint config\n",
        "if 'quantiles' in checkpoint['config']:\n",
        "    quantiles = checkpoint['config']['quantiles']\n",
        "elif 'quantile_regression' in checkpoint['config']:\n",
        "    quantiles = checkpoint['config']['quantile_regression']['quantiles']\n",
        "else:\n",
        "    # Default from problem statement\n",
        "    quantiles = [0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95]\n",
        "\n",
        "# Horizon names from checkpoint or default\n",
        "if 'horizon_names' in checkpoint['config']:\n",
        "    horizon_names = checkpoint['config']['horizon_names']\n",
        "elif 'horizons' in checkpoint['config'].get('model', {}):\n",
        "    horizon_names = checkpoint['config']['model']['horizons']\n",
        "else:\n",
        "    # Default from problem statement\n",
        "    horizon_names = ['15m', '30m', '60m', '2h', '4h']\n",
        "\n",
        "print(f\"Quantiles: {quantiles}\")\n",
        "print(f\"Horizons: {horizon_names}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1kj9VwUTdxN"
      },
      "source": [
        "## 6. Load Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh_D3AmqTdxN",
        "outputId": "dcbce30f-f3df-4bda-c918-8fbc1b853a66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from /content/drive/MyDrive/Colab Notebooks/Transformers/FP/data/processed/nq_features_full.parquet\n",
            "Features: 24\n",
            "Targets: 5\n",
            "Split statistics:\n",
            "  Train: 808,996 samples (2010-06-07 to 2021-12-31)\n",
            "  Val:   141,516 samples (2022-01-02 to 2023-12-29)\n",
            "  Test:  136,284 samples (2024-01-02 to 2025-12-03)\n",
            "\n",
            "Temporal gaps:\n",
            "  Train-Val gap: 49.1 hours\n",
            "  Val-Test gap: 74.1 hours\n",
            "  Purged samples: ~576 total (~288 per gap)\n",
            "[PASS] No data leakage detected:\n",
            "  Train-Val gap: 49.1 hours\n",
            "  Val-Test gap: 74.1 hours\n",
            "\n",
            "Dataset sizes:\n",
            "  Train: 80,870\n",
            "  Val:   14,122\n",
            "  Test:  13,599\n",
            "Test batches: 71\n",
            "Batch size: 192\n",
            "Approx samples: 13632\n"
          ]
        }
      ],
      "source": [
        "from data.dataset import NQDataModule\n",
        "\n",
        "data_module = NQDataModule(\n",
        "    data_path=paths['processed_data'] / 'nq_features_full.parquet',\n",
        "    batch_size=checkpoint['config']['training']['batch_size'],\n",
        "    num_workers=8,\n",
        "    pin_memory=True,\n",
        "    prefetch_factor=2,\n",
        "    persistent_workers=True,\n",
        "    subsample_fraction=0.10,\n",
        "    subsample_seed=42,\n",
        "    apply_subsample_to_all_splits=True\n",
        ")\n",
        "\n",
        "data_module.setup()\n",
        "test_loader = data_module.test_dataloader()\n",
        "\n",
        "print(f\"Test batches: {len(test_loader)}\")\n",
        "print(f\"Batch size: {checkpoint['config']['training']['batch_size']}\")\n",
        "print(f\"Approx samples: {len(test_loader) * checkpoint['config']['training']['batch_size']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQw3yZ7tTdxN"
      },
      "source": [
        "## 7. Run Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "orMup0axTdxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eeae8f9-d174-4e53-bdda-8fe51d407b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting: 100%|██████████| 71/71 [00:53<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predictions shape: (13599, 5, 7)\n",
            "Targets shape: (13599, 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from evaluation.inference import ModelPredictor\n",
        "\n",
        "print(\"Running inference...\")\n",
        "predictor = ModelPredictor(model, device)\n",
        "result = predictor.predict_dataset(test_loader, return_targets=True, show_progress=True)\n",
        "\n",
        "predictions = result['predictions']\n",
        "targets = result['targets']\n",
        "\n",
        "print(f\"\\nPredictions shape: {predictions.shape}\")\n",
        "print(f\"Targets shape: {targets.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwKhY3KvTdxO"
      },
      "source": [
        "## 8. Compute Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "obk4wOuETdxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a390bee5-feed-4c87-aadf-b8dd16037f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing metrics...\n",
            "\n",
            "Metrics by horizon:\n",
            "\n",
            "15m:\n",
            "  CRPS: 0.033306\n",
            "  IC: 0.0011\n",
            "  DA: 0.517\n",
            "\n",
            "30m:\n",
            "  CRPS: 0.001444\n",
            "  IC: -0.0060\n",
            "  DA: 0.518\n",
            "\n",
            "60m:\n",
            "  CRPS: 0.008692\n",
            "  IC: -0.0014\n",
            "  DA: 0.529\n",
            "\n",
            "2h:\n",
            "  CRPS: 0.012381\n",
            "  IC: -0.0226\n",
            "  DA: 0.536\n",
            "\n",
            "4h:\n",
            "  CRPS: 0.004305\n",
            "  IC: -0.0260\n",
            "  DA: 0.545\n"
          ]
        }
      ],
      "source": [
        "from evaluation.metrics import MetricsSummary\n",
        "\n",
        "print(\"Computing metrics...\")\n",
        "summary = MetricsSummary(quantiles=quantiles, horizon_names=horizon_names)\n",
        "metrics = summary.compute_all(predictions, targets)\n",
        "\n",
        "print(\"\\nMetrics by horizon:\")\n",
        "for h in horizon_names:\n",
        "    print(f\"\\n{h}:\")\n",
        "    print(f\"  CRPS: {metrics['distributional'][h]['crps']:.6f}\")\n",
        "    print(f\"  IC: {metrics['point'][h]['ic']:.4f}\")\n",
        "    print(f\"  DA: {metrics['point'][h]['da']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgxMasS-TdxP"
      },
      "source": [
        "## 9. Calibration Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fFxTZr8ZTdxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "951800bc-a1ad-4ade-c5a8-7f6234864285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calibration analysis...\n",
            "Saved: calibration_reliability.png\n",
            "\n",
            "Calibration metrics by horizon:\n",
            "  15m:\n",
            "    Mean error: 0.500000\n",
            "    Max error: 0.950000\n",
            "    RMSE: 0.609449\n",
            "  30m:\n",
            "    Mean error: 0.393354\n",
            "    Max error: 0.714913\n",
            "    RMSE: 0.471042\n",
            "  60m:\n",
            "    Mean error: 0.498193\n",
            "    Max error: 0.938749\n",
            "    RMSE: 0.606710\n",
            "  2h:\n",
            "    Mean error: 0.498456\n",
            "    Max error: 0.945294\n",
            "    RMSE: 0.607401\n",
            "  4h:\n",
            "    Mean error: 0.470586\n",
            "    Max error: 0.886613\n",
            "    RMSE: 0.575760\n"
          ]
        }
      ],
      "source": [
        "from evaluation.calibration import CalibrationByHorizon\n",
        "\n",
        "print(\"Calibration analysis...\")\n",
        "cal_analyzer = CalibrationByHorizon(quantiles, horizon_names)\n",
        "calibration_results = cal_analyzer.compute_per_horizon(predictions, targets)\n",
        "\n",
        "fig = cal_analyzer.plot_reliability_by_horizon(predictions, targets)\n",
        "plot_path = paths['results_dir'] / \"calibration_reliability.png\"\n",
        "fig.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
        "plt.close(fig)\n",
        "print(f\"Saved: {plot_path.name}\")\n",
        "\n",
        "print(\"\\nCalibration metrics by horizon:\")\n",
        "for h in horizon_names:\n",
        "    if h in calibration_results:\n",
        "        print(f\"  {h}:\")\n",
        "        print(f\"    Mean error: {calibration_results[h]['mean_error']:.6f}\")\n",
        "        print(f\"    Max error: {calibration_results[h]['max_error']:.6f}\")\n",
        "        print(f\"    RMSE: {calibration_results[h]['rmse']:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHCgFZ0ATdxP"
      },
      "source": [
        "## 10. Backtest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "X-kJ1p99TdxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82340fc7-08ff-4589-a2cd-30fd92f3a158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running backtest...\n",
            "\n",
            "Backtest summary:\n",
            "           sharpe   sortino  max_drawdown  profit_factor  hit_rate    calmar  total_return  n_trades  mean_return  std_return\n",
            "horizon                                                                                                                      \n",
            "15m      2.088242  2.966822      0.069485       1.051661  0.517023  5.801443      0.263772     13599     0.000018    0.001204\n",
            "30m      2.419255  3.374956      0.155986       1.058892  0.518494  4.578941      0.451304     13599     0.000029    0.001668\n",
            "60m      1.438116  1.950728      0.293658       1.034214  0.528862  1.812895      0.343300     13599     0.000025    0.002396\n",
            "2h       1.942117  2.639945      0.504079       1.045922  0.536363  2.459614      0.745920     13599     0.000047    0.003368\n",
            "4h       3.311340  4.523842      0.706536       1.076169  0.544746  9.106573      3.000511     13599     0.000114    0.004806\n",
            "\n",
            "Saved equity curves\n"
          ]
        }
      ],
      "source": [
        "from evaluation.backtest import MultiHorizonBacktester\n",
        "\n",
        "print(\"Running backtest...\")\n",
        "backtester = MultiHorizonBacktester(predictions, targets, horizon_names)\n",
        "bt_results = backtester.run()\n",
        "bt_summary = backtester.get_metrics_summary()\n",
        "\n",
        "print(\"\\nBacktest summary:\")\n",
        "print(bt_summary.to_string())\n",
        "\n",
        "bt_summary.to_csv(paths['results_dir'] / 'backtest_summary.csv')\n",
        "\n",
        "ax = backtester.plot_equity_curves()\n",
        "fig = ax.get_figure()\n",
        "fig.savefig(paths['results_dir'] / 'equity_curves.png', dpi=150, bbox_inches='tight')\n",
        "plt.close(fig)\n",
        "print(\"\\nSaved equity curves\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czqNISsRTdxQ"
      },
      "source": [
        "## 11. Generate Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iIuilOHCTdxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14fccfcf-bba4-4d7a-8105-e19a121cf7c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# MIGT-TVDT Evaluation Report\n",
            "\n",
            "**Date:** 2025-12-09 04:38:40\n",
            "\n",
            "## Training Info\n",
            "- Epochs: 2\n",
            "- Val loss: 0.014659\n",
            "- Subsample: 10%\n",
            "\n",
            "## Architecture\n",
            "- Variables: 24\n",
            "- Max seq len: 288\n",
            "- Horizons: ['15m', '30m', '60m', '2h', '4h']\n",
            "- Quantiles: 7\n",
            "- d_model: 256\n",
            "- Parameters: 6,866,984\n",
            "\n",
            "## Test Set\n",
            "- Samples: 13,599\n",
            "\n",
            "---\n",
            "\n",
            "# Model Evaluation Report\n",
            "\n",
            "Samples evaluated: 13,599\n",
            "\n",
            "\n",
            "## Distributional Metrics\n",
            "\n",
            "| Horizon | CRPS | PICP-80 | PICP-50 | MPIW-80 | MPIW-50 |\n",
            "|---------|------|---------|---------|---------|---------|\n",
            "| 15m | 0.03331 | 0.000 | 0.000 | 0.00689 | 0.00314 |\n",
            "| 30m | 0.00144 | 0.169 | 0.026 | 0.00772 | 0.00315 |\n",
            "| 60m | 0.00869 | 0.001 | 0.000 | 0.00755 | 0.00346 |\n",
            "| 2h | 0.01238 | 0.003 | 0.001 | 0.00652 | 0.00294 |\n",
            "| 4h | 0.00431 | 0.030 | 0.017 | 0.00487 | 0.00254 |\n",
            "\n",
            "## Point Metrics (Median)\n",
            "\n",
            "| Horizon | IC | DA | RMSE | MAE |\n",
            "|---------|----|----|------|-----|\n",
            "| 15m | 0.0011 | 0.517 | 0.07021 | 0.07016 |\n",
            "| 30m | -0.0060 | 0.518 | 0.00488 | 0.00447 |\n",
            "| 60m | -0.0014 | 0.529 | 0.02135 | 0.02116 |\n",
            "| 2h | -0.0226 | 0.536 | 0.02702 | 0.02668 |\n",
            "| 4h | -0.0260 | 0.545 | 0.01087 | 0.00989 |\n",
            "\n",
            "## Calibration Summary\n",
            "\n",
            "- Mean calibration error: 0.4721\n",
            "- Max calibration error: 0.8539\n",
            "## Backtest Results\n",
            "\n",
            "           sharpe   sortino  max_drawdown  profit_factor  hit_rate    calmar  total_return  n_trades  mean_return  std_return\n",
            "horizon                                                                                                                      \n",
            "15m      2.088242  2.966822      0.069485       1.051661  0.517023  5.801443      0.263772     13599     0.000018    0.001204\n",
            "30m      2.419255  3.374956      0.155986       1.058892  0.518494  4.578941      0.451304     13599     0.000029    0.001668\n",
            "60m      1.438116  1.950728      0.293658       1.034214  0.528862  1.812895      0.343300     13599     0.000025    0.002396\n",
            "2h       1.942117  2.639945      0.504079       1.045922  0.536363  2.459614      0.745920     13599     0.000047    0.003368\n",
            "4h       3.311340  4.523842      0.706536       1.076169  0.544746  9.106573      3.000511     13599     0.000114    0.004806\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from evaluation.inference import format_evaluation_report\n",
        "\n",
        "eval_results = {\n",
        "    'n_samples': len(targets),\n",
        "    'metrics': metrics\n",
        "}\n",
        "\n",
        "report = format_evaluation_report(eval_results, horizon_names)\n",
        "\n",
        "header = f\"\"\"# MIGT-TVDT Evaluation Report\n",
        "\n",
        "**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "## Training Info\n",
        "- Epochs: {checkpoint['epoch']}\n",
        "- Val loss: {checkpoint['val_loss']:.6f}\n",
        "- Subsample: {checkpoint['config']['data'].get('subsample_fraction', 1.0)*100:.0f}%\n",
        "\n",
        "## Architecture\n",
        "- Variables: {model_config['n_variables']}\n",
        "- Max seq len: {model_config['max_seq_len']}\n",
        "- Horizons: {horizon_names}\n",
        "- Quantiles: {len(quantiles)}\n",
        "- d_model: {model_config['d_model']}\n",
        "- Parameters: {n_params:,}\n",
        "\n",
        "## Test Set\n",
        "- Samples: {len(targets):,}\n",
        "\n",
        "---\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Add backtest section\n",
        "backtest_section = \"\\n## Backtest Results\\n\\n\"\n",
        "backtest_section += bt_summary.to_string()\n",
        "backtest_section += \"\\n\"\n",
        "\n",
        "full_report = header + report + backtest_section\n",
        "\n",
        "report_path = paths['results_dir'] / 'evaluation_report.md'\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(full_report)\n",
        "\n",
        "print(full_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvWOGOVsTdxQ"
      },
      "source": [
        "## 12. Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "X20oN2ExTdxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "119ffd1b-7dad-4706-87f2-0d638a940844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "All results saved to: /content/drive/MyDrive/Colab Notebooks/Transformers/FP/evaluation_results\n"
          ]
        }
      ],
      "source": [
        "# Save predictions\n",
        "np.savez_compressed(\n",
        "    paths['results_dir'] / 'predictions_targets.npz',\n",
        "    predictions=predictions,\n",
        "    targets=targets\n",
        ")\n",
        "\n",
        "# Helper for JSON serialization\n",
        "def to_serializable(obj):\n",
        "    if isinstance(obj, dict):\n",
        "        return {k: to_serializable(v) for k, v in obj.items()}\n",
        "    elif isinstance(obj, (np.integer, np.floating)):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    elif isinstance(obj, pd.DataFrame):\n",
        "        return obj.to_dict('records')\n",
        "    return obj\n",
        "\n",
        "# Save metrics\n",
        "with open(paths['results_dir'] / 'metrics.json', 'w') as f:\n",
        "    json.dump(to_serializable(metrics), f, indent=2)\n",
        "\n",
        "# Save calibration\n",
        "with open(paths['results_dir'] / 'calibration.json', 'w') as f:\n",
        "    json.dump(to_serializable(calibration_results), f, indent=2)\n",
        "\n",
        "# Save backtest\n",
        "with open(paths['results_dir'] / 'backtest.json', 'w') as f:\n",
        "    json.dump(to_serializable(bt_results), f, indent=2)\n",
        "\n",
        "# Metrics CSV\n",
        "rows = []\n",
        "for cat in ['distributional', 'point']:\n",
        "    if cat in metrics:\n",
        "        for h, m in metrics[cat].items():\n",
        "            row = {'category': cat, 'horizon': h}\n",
        "            for k, v in m.items():\n",
        "                row[k] = float(v) if isinstance(v, (np.integer, np.floating)) else v\n",
        "            rows.append(row)\n",
        "\n",
        "pd.DataFrame(rows).to_csv(paths['results_dir'] / 'metrics_summary.csv', index=False)\n",
        "\n",
        "print(\"\\nAll results saved to:\", paths['results_dir'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KchMmLRTdxR"
      },
      "source": [
        "## 13. Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "V0eFUU7wTdxS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f517797-cc45-4e98-fb12-8c440ce25e88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "EVALUATION COMPLETE\n",
            "============================================================\n",
            "\n",
            "Key Metrics:\n",
            "\n",
            "15m:\n",
            "  IC: 0.0011\n",
            "  DA: 0.517\n",
            "  CRPS: 0.033306\n",
            "\n",
            "30m:\n",
            "  IC: -0.0060\n",
            "  DA: 0.518\n",
            "  CRPS: 0.001444\n",
            "\n",
            "60m:\n",
            "  IC: -0.0014\n",
            "  DA: 0.529\n",
            "  CRPS: 0.008692\n",
            "\n",
            "2h:\n",
            "  IC: -0.0226\n",
            "  DA: 0.536\n",
            "  CRPS: 0.012381\n",
            "\n",
            "4h:\n",
            "  IC: -0.0260\n",
            "  DA: 0.545\n",
            "  CRPS: 0.004305\n",
            "\n",
            "Backtest Performance:\n",
            "  15m: Sharpe=2.088, Max DD=6.95%\n",
            "  30m: Sharpe=2.419, Max DD=15.60%\n",
            "  60m: Sharpe=1.438, Max DD=29.37%\n",
            "  2h: Sharpe=1.942, Max DD=50.41%\n",
            "  4h: Sharpe=3.311, Max DD=70.65%\n",
            "\n",
            "Results: /content/drive/MyDrive/Colab Notebooks/Transformers/FP/evaluation_results\n",
            "\n",
            "Files:\n",
            "  calibration_reliability.png: 110.6 KB\n",
            "  backtest_summary.csv: 1.0 KB\n",
            "  equity_curves.png: 178.9 KB\n",
            "  evaluation_report.md: 2.1 KB\n",
            "  predictions_targets.npz: 1798.9 KB\n",
            "  metrics.json: 2.4 KB\n",
            "  calibration.json: 1.7 KB\n",
            "  backtest.json: 5374.3 KB\n",
            "  metrics_summary.csv: 1.1 KB\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"EVALUATION COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nKey Metrics:\")\n",
        "for h in horizon_names:\n",
        "    print(f\"\\n{h}:\")\n",
        "    print(f\"  IC: {metrics['point'][h]['ic']:.4f}\")\n",
        "    print(f\"  DA: {metrics['point'][h]['da']:.3f}\")\n",
        "    print(f\"  CRPS: {metrics['distributional'][h]['crps']:.6f}\")\n",
        "\n",
        "print(f\"\\nBacktest Performance:\")\n",
        "for h in horizon_names:\n",
        "    if h in bt_summary.index:\n",
        "        sharpe = bt_summary.loc[h, 'sharpe']\n",
        "        max_dd = bt_summary.loc[h, 'max_drawdown']\n",
        "        print(f\"  {h}: Sharpe={sharpe:.3f}, Max DD={max_dd:.2%}\")\n",
        "\n",
        "print(f\"\\nResults: {paths['results_dir']}\")\n",
        "print(\"\\nFiles:\")\n",
        "for f in paths['results_dir'].glob('*'):\n",
        "    print(f\"  {f.name}: {f.stat().st_size/1024:.1f} KB\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}