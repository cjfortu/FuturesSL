{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Phase 3: Dataset & DataLoader Testing\n",
        "\n",
        "Tests the complete data pipeline with functional scope:\n",
        "- Data preprocessing (windowing, padding, normalization)\n",
        "- PyTorch Dataset implementation\n",
        "- DataModule and DataLoader functionality\n",
        "- Integration with model requirements\n",
        "\n",
        "**Environment:** Google Colab with A100 GPU\n",
        "**Expected execution time:** ~5-10 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mount",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47fd4094-1413-4131-96cf-253b42d384c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "setup_paths",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e1595f7-85c2-451d-c588-c811afb294a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base: /content/drive/MyDrive/Colab Notebooks/Transformers/FP\n",
            "Data: /content/drive/MyDrive/Colab Notebooks/Transformers/FP/data/processed\n",
            "Src: /content/drive/MyDrive/Colab Notebooks/Transformers/FP/src\n"
          ]
        }
      ],
      "source": [
        "# Setup paths and imports\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "BASE_DIR = Path(\"/content/drive/MyDrive/Colab Notebooks/Transformers/FP\")\n",
        "DATA_DIR = BASE_DIR / \"data\" / \"processed\"\n",
        "SRC_DIR = BASE_DIR / \"src\"\n",
        "\n",
        "sys.path.insert(0, str(SRC_DIR))\n",
        "\n",
        "print(f\"Base: {BASE_DIR}\")\n",
        "print(f\"Data: {DATA_DIR}\")\n",
        "print(f\"Src: {SRC_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "imports",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57dc9e08-449b-4042-f2b0-ba0d5e1427cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch: 2.9.0+cu126\n",
            "CUDA: True\n",
            "GPU: NVIDIA A100-SXM4-80GB\n"
          ]
        }
      ],
      "source": [
        "# Core imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from typing import Dict, Tuple\n",
        "\n",
        "from data.preprocessing import DataPreprocessor\n",
        "from data.dataset import NQFuturesDataset, NQDataModule, collate_fn\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "load_section"
      },
      "source": [
        "## 1. Load and Validate Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "load_data",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df26c39e-76be-4778-fde4-7c80ee3ae360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (1086808, 29)\n",
            "Date range: 2010-06-07 to 2025-12-03\n",
            "Features: 24\n",
            "Targets: 5\n",
            "\n",
            "[PASS] Data loaded and validated\n"
          ]
        }
      ],
      "source": [
        "def load_and_validate_data(data_path: Path) -> Tuple[pd.DataFrame, list, list]:\n",
        "    \"\"\"\n",
        "    Load feature data and identify columns.\n",
        "\n",
        "    Returns:\n",
        "        df, feature_cols, target_cols\n",
        "    \"\"\"\n",
        "    df = pd.read_parquet(data_path)\n",
        "\n",
        "    target_cols = ['target_15m', 'target_30m', 'target_60m', 'target_2h', 'target_4h']\n",
        "    feature_cols = [col for col in df.columns if col not in target_cols]\n",
        "\n",
        "    print(f\"Data shape: {df.shape}\")\n",
        "    print(f\"Date range: {df.index.min().date()} to {df.index.max().date()}\")\n",
        "    print(f\"Features: {len(feature_cols)}\")\n",
        "    print(f\"Targets: {len(target_cols)}\")\n",
        "\n",
        "    assert len(feature_cols) == 24, f\"Expected 24 features, got {len(feature_cols)}\"\n",
        "    assert len(target_cols) == 5, f\"Expected 5 targets, got {len(target_cols)}\"\n",
        "    print(\"\\n[PASS] Data loaded and validated\")\n",
        "\n",
        "    return df, feature_cols, target_cols\n",
        "\n",
        "# Execute\n",
        "data_path = DATA_DIR / \"nq_features_full.parquet\"\n",
        "df, feature_cols, target_cols = load_and_validate_data(data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "preprocessor_section"
      },
      "source": [
        "## 2. Test DataPreprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "test_window_creation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6cce1c2-37e8-42c1-dd60-9f9ca647b769"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Window created for 2010-06-09 14:20:00+00:00\n",
            "  Features: (288, 24)\n",
            "  Attention mask: (288,)\n",
            "  Actual length: 279\n",
            "  Pad length: 9\n",
            "\n",
            "[PASS] Window creation validated\n"
          ]
        }
      ],
      "source": [
        "def test_window_creation(\n",
        "    df: pd.DataFrame,\n",
        "    feature_cols: list,\n",
        "    target_cols: list\n",
        ") -> DataPreprocessor:\n",
        "    \"\"\"\n",
        "    Test window creation with 24h lookback.\n",
        "\n",
        "    Returns:\n",
        "        Initialized preprocessor\n",
        "    \"\"\"\n",
        "    preprocessor = DataPreprocessor(\n",
        "        max_seq_len=288,\n",
        "        feature_cols=feature_cols,\n",
        "        target_cols=target_cols\n",
        "    )\n",
        "\n",
        "    # Test with timestamp well into dataset\n",
        "    test_timestamp = df.index[df.index >= df.index.min() + pd.Timedelta(hours=48)][100]\n",
        "\n",
        "    features, attention_mask, metadata = preprocessor.create_window(df, test_timestamp)\n",
        "\n",
        "    print(f\"Window created for {test_timestamp}\")\n",
        "    print(f\"  Features: {features.shape}\")\n",
        "    print(f\"  Attention mask: {attention_mask.shape}\")\n",
        "    print(f\"  Actual length: {metadata['actual_length']}\")\n",
        "    print(f\"  Pad length: {metadata['pad_length']}\")\n",
        "\n",
        "    # Validate\n",
        "    assert features.shape == (288, 24), f\"Expected (288, 24), got {features.shape}\"\n",
        "    assert attention_mask.shape == (288,), f\"Expected (288,), got {attention_mask.shape}\"\n",
        "    assert metadata['actual_length'] == attention_mask.sum()\n",
        "    assert 273 <= metadata['actual_length'] <= 288\n",
        "\n",
        "    print(\"\\n[PASS] Window creation validated\")\n",
        "    return preprocessor\n",
        "\n",
        "# Execute\n",
        "preprocessor = test_window_creation(df, feature_cols, target_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "test_normalization",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b172e622-1747-4d4a-906e-e1e5e0da7ad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalization statistics:\n",
            "  Mean range: [-5.05e-07, 7.12e-05]\n",
            "  Std range: [0.0000, 1.0000]\n",
            "\n",
            "Feature variance distribution:\n",
            "  Normal variance (std > 1e-05): 22 features\n",
            "  Low variance (std <= 1e-05): 2 features\n",
            "[PASS] Normal features normalized to std ~ 1\n",
            "  Range: [1.0000, 1.0000]\n",
            "[PASS] Low-variance features remain small\n",
            "  Max std: 1.25e-06\n",
            "\n",
            "[PASS] Normalization validated\n"
          ]
        }
      ],
      "source": [
        "def test_normalization(\n",
        "    df: pd.DataFrame,\n",
        "    preprocessor: DataPreprocessor\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Test RevIN normalization with low-variance handling.\n",
        "    \"\"\"\n",
        "    # Get test window\n",
        "    test_timestamp = df.index[1000]\n",
        "    features, attention_mask, _ = preprocessor.create_window(df, test_timestamp)\n",
        "\n",
        "    # Normalize\n",
        "    normalized, norm_stats = preprocessor.normalize_window(\n",
        "        features, attention_mask, store_stats=True\n",
        "    )\n",
        "\n",
        "    # Extract valid positions only\n",
        "    valid_normalized = normalized[attention_mask]\n",
        "    padding_features = normalized[~attention_mask]\n",
        "\n",
        "    # Compute statistics\n",
        "    normalized_means = valid_normalized.mean(axis=0)\n",
        "    normalized_stds = valid_normalized.std(axis=0)\n",
        "\n",
        "    print(\"Normalization statistics:\")\n",
        "    print(f\"  Mean range: [{normalized_means.min():.2e}, {normalized_means.max():.2e}]\")\n",
        "    print(f\"  Std range: [{normalized_stds.min():.4f}, {normalized_stds.max():.4f}]\")\n",
        "\n",
        "    # Validate padding remains zero\n",
        "    assert np.allclose(padding_features, 0), \"Padding should remain zeros\"\n",
        "\n",
        "    # Validate centering (all features)\n",
        "    assert np.allclose(normalized_means, 0, atol=1e-3), \\\n",
        "        f\"Means not near zero: range [{normalized_means.min():.2e}, {normalized_means.max():.2e}]\"\n",
        "\n",
        "    # Separate by variance\n",
        "    eps = norm_stats['eps']\n",
        "    original_stds = norm_stats['std']\n",
        "    normal_mask = original_stds > eps\n",
        "    low_var_mask = original_stds <= eps\n",
        "\n",
        "    print(f\"\\nFeature variance distribution:\")\n",
        "    print(f\"  Normal variance (std > {eps}): {normal_mask.sum()} features\")\n",
        "    print(f\"  Low variance (std <= {eps}): {low_var_mask.sum()} features\")\n",
        "\n",
        "    # Validate normal features\n",
        "    if normal_mask.sum() > 0:\n",
        "        normal_stds = normalized_stds[normal_mask]\n",
        "        assert np.allclose(normal_stds, 1, atol=0.1), \\\n",
        "            f\"Normal features std not ~1: range [{normal_stds.min():.3f}, {normal_stds.max():.3f}]\"\n",
        "        print(f\"[PASS] Normal features normalized to std ~ 1\")\n",
        "        print(f\"  Range: [{normal_stds.min():.4f}, {normal_stds.max():.4f}]\")\n",
        "\n",
        "    # Validate low-variance features\n",
        "    if low_var_mask.sum() > 0:\n",
        "        low_var_stds = normalized_stds[low_var_mask]\n",
        "        assert np.all(low_var_stds < 0.1), \\\n",
        "            f\"Low-var features amplified: max std {low_var_stds.max():.2e}\"\n",
        "        print(f\"[PASS] Low-variance features remain small\")\n",
        "        print(f\"  Max std: {low_var_stds.max():.2e}\")\n",
        "\n",
        "    print(\"\\n[PASS] Normalization validated\")\n",
        "\n",
        "# Execute\n",
        "test_normalization(df, preprocessor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "test_temporal_info",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e58dfa0-25d7-41ab-c5b4-30ceeff32454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temporal information:\n",
            "  bar_in_day shape: (278,)\n",
            "  bar_in_day range: [0, 287]\n",
            "  day_of_week: 3\n",
            "  day_of_month: 10\n",
            "  day_of_year: 161\n",
            "\n",
            "[PASS] Temporal info validated\n"
          ]
        }
      ],
      "source": [
        "def test_temporal_info(\n",
        "    df: pd.DataFrame,\n",
        "    preprocessor: DataPreprocessor\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Test temporal information extraction.\n",
        "    \"\"\"\n",
        "    test_timestamp = df.index[1000]\n",
        "    _, _, metadata = preprocessor.create_window(df, test_timestamp)\n",
        "\n",
        "    temporal_info = preprocessor.extract_temporal_info(\n",
        "        metadata['timestamps'], test_timestamp\n",
        "    )\n",
        "\n",
        "    print(\"Temporal information:\")\n",
        "    print(f\"  bar_in_day shape: {temporal_info['bar_in_day'].shape}\")\n",
        "    print(f\"  bar_in_day range: [{temporal_info['bar_in_day'].min()}, {temporal_info['bar_in_day'].max()}]\")\n",
        "    print(f\"  day_of_week: {temporal_info['day_of_week']}\")\n",
        "    print(f\"  day_of_month: {temporal_info['day_of_month']}\")\n",
        "    print(f\"  day_of_year: {temporal_info['day_of_year']}\")\n",
        "\n",
        "    # Validate ranges\n",
        "    assert 0 <= temporal_info['bar_in_day'].min() <= temporal_info['bar_in_day'].max() < 288\n",
        "    assert 0 <= temporal_info['day_of_week'] <= 4\n",
        "    assert 1 <= temporal_info['day_of_month'] <= 31\n",
        "    assert 1 <= temporal_info['day_of_year'] <= 366\n",
        "\n",
        "    print(\"\\n[PASS] Temporal info validated\")\n",
        "\n",
        "# Execute\n",
        "test_temporal_info(df, preprocessor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "test_splits",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "148631ee-31bb-45b6-97b8-516198a750a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split statistics:\n",
            "  Train: 808,996 samples (2010-06-07 to 2021-12-31)\n",
            "  Val:   141,516 samples (2022-01-02 to 2023-12-29)\n",
            "  Test:  136,284 samples (2024-01-02 to 2025-12-03)\n",
            "\n",
            "Temporal gaps:\n",
            "  Train-Val gap: 49.1 hours\n",
            "  Val-Test gap: 74.1 hours\n",
            "  Purged samples: ~576 total (~288 per gap)\n",
            "[PASS] No data leakage detected:\n",
            "  Train-Val gap: 49.1 hours\n",
            "  Val-Test gap: 74.1 hours\n",
            "\n",
            "[PASS] Splits created with proper temporal separation\n"
          ]
        }
      ],
      "source": [
        "def test_splits_and_leakage(\n",
        "    df: pd.DataFrame,\n",
        "    preprocessor: DataPreprocessor\n",
        ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Test train/val/test splits with leakage validation.\n",
        "\n",
        "    Returns:\n",
        "        train_df, val_df, test_df\n",
        "    \"\"\"\n",
        "    # Create splits with purge gaps\n",
        "    train_df, val_df, test_df = preprocessor.create_splits(\n",
        "        df, train_end='2021-12-31', val_end='2023-12-31'\n",
        "    )\n",
        "\n",
        "    # Validate no leakage\n",
        "    leakage_ok = preprocessor.validate_no_leakage(\n",
        "        train_df, val_df, test_df, tolerance_hours=24\n",
        "    )\n",
        "\n",
        "    print(f\"\\n[PASS] Splits created with proper temporal separation\")\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "# Execute\n",
        "train_df, val_df, test_df = test_splits_and_leakage(df, preprocessor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dataset_section"
      },
      "source": [
        "## 3. Test PyTorch Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "test_dataset",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd324233-4f36-4040-a387-8b1c734136f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset length: 808,708\n",
            "\n",
            "Sample structure:\n",
            "  features: torch.Size([288, 24])\n",
            "  attention_mask: torch.Size([288])\n",
            "  targets: torch.Size([5])\n",
            "  bar_in_day: torch.Size([279])\n",
            "  day_of_week: 1\n",
            "\n",
            "[PASS] Dataset implementation validated\n"
          ]
        }
      ],
      "source": [
        "def test_pytorch_dataset(\n",
        "    train_df: pd.DataFrame,\n",
        "    feature_cols: list,\n",
        "    target_cols: list,\n",
        "    preprocessor: DataPreprocessor\n",
        ") -> NQFuturesDataset:\n",
        "    \"\"\"\n",
        "    Test NQFuturesDataset implementation.\n",
        "\n",
        "    Returns:\n",
        "        Dataset instance\n",
        "    \"\"\"\n",
        "    dataset = NQFuturesDataset(\n",
        "        train_df, feature_cols, target_cols, preprocessor\n",
        "    )\n",
        "\n",
        "    print(f\"Dataset length: {len(dataset):,}\")\n",
        "\n",
        "    # Test sample access\n",
        "    sample = dataset[0]\n",
        "\n",
        "    print(\"\\nSample structure:\")\n",
        "    print(f\"  features: {sample['features'].shape}\")\n",
        "    print(f\"  attention_mask: {sample['attention_mask'].shape}\")\n",
        "    print(f\"  targets: {sample['targets'].shape}\")\n",
        "    print(f\"  bar_in_day: {sample['bar_in_day'].shape}\")\n",
        "    print(f\"  day_of_week: {sample['day_of_week']}\")\n",
        "\n",
        "    # Validate shapes\n",
        "    assert sample['features'].shape == (288, 24)\n",
        "    assert sample['attention_mask'].shape == (288,)\n",
        "    assert sample['targets'].shape == (5,)\n",
        "    assert len(sample['bar_in_day'].shape) == 1\n",
        "\n",
        "    print(\"\\n[PASS] Dataset implementation validated\")\n",
        "    return dataset\n",
        "\n",
        "# Execute\n",
        "train_dataset = test_pytorch_dataset(train_df, feature_cols, target_cols, preprocessor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "datamodule_section"
      },
      "source": [
        "## 4. Test DataModule & DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "test_datamodule",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4c29c66-ce74-4a97-ada3-90a12e71db26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from /content/drive/MyDrive/Colab Notebooks/Transformers/FP/data/processed/nq_features_full.parquet\n",
            "Features: 24\n",
            "Targets: 5\n",
            "Split statistics:\n",
            "  Train: 808,996 samples (2010-06-07 to 2021-12-31)\n",
            "  Val:   141,516 samples (2022-01-02 to 2023-12-29)\n",
            "  Test:  136,284 samples (2024-01-02 to 2025-12-03)\n",
            "\n",
            "Temporal gaps:\n",
            "  Train-Val gap: 49.1 hours\n",
            "  Val-Test gap: 74.1 hours\n",
            "  Purged samples: ~576 total (~288 per gap)\n",
            "[PASS] No data leakage detected:\n",
            "  Train-Val gap: 49.1 hours\n",
            "  Val-Test gap: 74.1 hours\n",
            "\n",
            "Dataset sizes:\n",
            "  Train: 808,708\n",
            "  Val:   141,228\n",
            "  Test:  135,996\n",
            "\n",
            "Dataset sizes:\n",
            "  Train: 808,708\n",
            "  Val: 141,228\n",
            "  Test: 135,996\n",
            "\n",
            "[PASS] DataModule setup complete\n"
          ]
        }
      ],
      "source": [
        "def test_data_module(\n",
        "    data_path: Path\n",
        ") -> NQDataModule:\n",
        "    \"\"\"\n",
        "    Test NQDataModule with proper setup.\n",
        "\n",
        "    Returns:\n",
        "        Initialized data module\n",
        "    \"\"\"\n",
        "    data_module = NQDataModule(\n",
        "        data_path=data_path,\n",
        "        batch_size=32,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        max_seq_len=288,\n",
        "        train_end='2021-12-31',\n",
        "        val_end='2023-12-31'\n",
        "    )\n",
        "\n",
        "    # Setup (loads data, creates splits)\n",
        "    data_module.setup()\n",
        "\n",
        "    print(f\"\\nDataset sizes:\")\n",
        "    print(f\"  Train: {len(data_module.train_dataset):,}\")\n",
        "    print(f\"  Val: {len(data_module.val_dataset):,}\")\n",
        "    print(f\"  Test: {len(data_module.test_dataset):,}\")\n",
        "\n",
        "    print(\"\\n[PASS] DataModule setup complete\")\n",
        "    return data_module\n",
        "\n",
        "# Execute\n",
        "data_module = test_data_module(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "test_dataloaders",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c645a808-5434-431b-aa93-e2a600454da8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader: 25272 batches\n",
            "Val loader: 4414 batches\n",
            "\n",
            "Batch structure:\n",
            "  features: torch.Size([32, 288, 24])\n",
            "  attention_mask: torch.Size([32, 288])\n",
            "  targets: torch.Size([32, 5])\n",
            "  bar_in_day: torch.Size([32, 288])\n",
            "\n",
            "[PASS] DataLoaders validated\n"
          ]
        }
      ],
      "source": [
        "def test_dataloaders(\n",
        "    data_module: NQDataModule\n",
        ") -> Dict:\n",
        "    \"\"\"\n",
        "    Test DataLoader functionality and batch loading.\n",
        "\n",
        "    Returns:\n",
        "        Sample batch from train loader\n",
        "    \"\"\"\n",
        "    train_loader = data_module.train_dataloader()\n",
        "    val_loader = data_module.val_dataloader()\n",
        "\n",
        "    print(f\"Train loader: {len(train_loader)} batches\")\n",
        "    print(f\"Val loader: {len(val_loader)} batches\")\n",
        "\n",
        "    # Test batch loading\n",
        "    batch = next(iter(train_loader))\n",
        "\n",
        "    print(\"\\nBatch structure:\")\n",
        "    print(f\"  features: {batch['features'].shape}\")\n",
        "    print(f\"  attention_mask: {batch['attention_mask'].shape}\")\n",
        "    print(f\"  targets: {batch['targets'].shape}\")\n",
        "    print(f\"  bar_in_day: {batch['bar_in_day'].shape}\")\n",
        "\n",
        "    # Validate batch shapes\n",
        "    B = batch['features'].shape[0]\n",
        "    assert batch['features'].shape == (B, 288, 24)\n",
        "    assert batch['attention_mask'].shape == (B, 288)\n",
        "    assert batch['targets'].shape == (B, 5)\n",
        "\n",
        "    print(\"\\n[PASS] DataLoaders validated\")\n",
        "    return batch\n",
        "\n",
        "# Execute\n",
        "sample_batch = test_dataloaders(data_module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "integration_section"
      },
      "source": [
        "## 5. Integration Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "test_gpu_transfer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1784b61-1b67-48e8-d4e8-f2b55db9f27f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU transfer successful:\n",
            "  Features device: cuda:0\n",
            "  Mask device: cuda:0\n",
            "  Targets device: cuda:0\n",
            "\n",
            "[PASS] GPU transfer validated\n"
          ]
        }
      ],
      "source": [
        "def test_gpu_transfer(batch: Dict) -> None:\n",
        "    \"\"\"\n",
        "    Test GPU transfer if available.\n",
        "    \"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"No GPU available, skipping GPU tests\")\n",
        "        return\n",
        "\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "    # Transfer batch\n",
        "    features_gpu = batch['features'].to(device)\n",
        "    mask_gpu = batch['attention_mask'].to(device)\n",
        "    targets_gpu = batch['targets'].to(device)\n",
        "\n",
        "    print(f\"GPU transfer successful:\")\n",
        "    print(f\"  Features device: {features_gpu.device}\")\n",
        "    print(f\"  Mask device: {mask_gpu.device}\")\n",
        "    print(f\"  Targets device: {targets_gpu.device}\")\n",
        "\n",
        "    print(\"\\n[PASS] GPU transfer validated\")\n",
        "\n",
        "# Execute\n",
        "test_gpu_transfer(sample_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "test_memory",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4830f1e-6e01-48dd-9405-f4a2b1eec944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from /content/drive/MyDrive/Colab Notebooks/Transformers/FP/data/processed/nq_features_full.parquet\n",
            "Features: 24\n",
            "Targets: 5\n",
            "Split statistics:\n",
            "  Train: 808,996 samples (2010-06-07 to 2021-12-31)\n",
            "  Val:   141,516 samples (2022-01-02 to 2023-12-29)\n",
            "  Test:  136,284 samples (2024-01-02 to 2025-12-03)\n",
            "\n",
            "Temporal gaps:\n",
            "  Train-Val gap: 49.1 hours\n",
            "  Val-Test gap: 74.1 hours\n",
            "  Purged samples: ~576 total (~288 per gap)\n",
            "[PASS] No data leakage detected:\n",
            "  Train-Val gap: 49.1 hours\n",
            "  Val-Test gap: 74.1 hours\n",
            "\n",
            "Dataset sizes:\n",
            "  Train: 808,708\n",
            "  Val:   141,228\n",
            "  Test:  135,996\n",
            "Large batch test (batch_size=128):\n",
            "  Features: torch.Size([128, 288, 24])\n",
            "  Memory: 3.38 MB\n",
            "  GPU allocated: 3.55 MB\n",
            "  GPU reserved: 22.00 MB\n",
            "\n",
            "[PASS] Memory footprint acceptable for A100\n"
          ]
        }
      ],
      "source": [
        "def test_memory_footprint(data_path: Path) -> None:\n",
        "    \"\"\"\n",
        "    Test memory usage with production batch size.\n",
        "    \"\"\"\n",
        "    import gc\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    # Create module with production batch size\n",
        "    data_module_large = NQDataModule(\n",
        "        data_path=data_path,\n",
        "        batch_size=128,\n",
        "        num_workers=0,\n",
        "        pin_memory=False\n",
        "    )\n",
        "    data_module_large.setup()\n",
        "\n",
        "    loader = data_module_large.train_dataloader()\n",
        "    batch_large = next(iter(loader))\n",
        "\n",
        "    memory_mb = batch_large['features'].element_size() * batch_large['features'].nelement() / 1024**2\n",
        "\n",
        "    print(f\"Large batch test (batch_size=128):\")\n",
        "    print(f\"  Features: {batch_large['features'].shape}\")\n",
        "    print(f\"  Memory: {memory_mb:.2f} MB\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        batch_large_gpu = {k: v.to(device) if isinstance(v, torch.Tensor) else v\n",
        "                          for k, v in batch_large.items()}\n",
        "        print(f\"  GPU allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
        "        print(f\"  GPU reserved: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
        "\n",
        "    print(\"\\n[PASS] Memory footprint acceptable for A100\")\n",
        "\n",
        "# Execute\n",
        "test_memory_footprint(data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quality_section"
      },
      "source": [
        "## 6. Data Quality Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "test_target_stats",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d7a8e0-c0bb-4961-d218-cadb42a8d942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train target statistics:\n",
            "  target_15m:\n",
            "    Mean: 0.000063\n",
            "    Std: 0.001949\n",
            "  target_30m:\n",
            "    Mean: 0.000128\n",
            "    Std: 0.002769\n",
            "  target_60m:\n",
            "    Mean: 0.000264\n",
            "    Std: 0.004069\n",
            "  target_2h:\n",
            "    Mean: 0.000552\n",
            "    Std: 0.005530\n",
            "  target_4h:\n",
            "    Mean: 0.001264\n",
            "    Std: 0.006850\n",
            "\n",
            "Validation target statistics:\n",
            "  target_15m:\n",
            "    Mean: -0.000140\n",
            "    Std: 0.001496\n",
            "  target_30m:\n",
            "    Mean: -0.000272\n",
            "    Std: 0.002136\n",
            "  target_60m:\n",
            "    Mean: -0.000551\n",
            "    Std: 0.002969\n",
            "  target_2h:\n",
            "    Mean: -0.001227\n",
            "    Std: 0.004456\n",
            "  target_4h:\n",
            "    Mean: -0.002528\n",
            "    Std: 0.006672\n",
            "\n",
            "Test target statistics:\n",
            "  target_15m:\n",
            "    Mean: -0.000013\n",
            "    Std: 0.000881\n",
            "  target_30m:\n",
            "    Mean: -0.000023\n",
            "    Std: 0.001281\n",
            "  target_60m:\n",
            "    Mean: -0.000043\n",
            "    Std: 0.001887\n",
            "  target_2h:\n",
            "    Mean: -0.000069\n",
            "    Std: 0.002742\n",
            "  target_4h:\n",
            "    Mean: -0.000046\n",
            "    Std: 0.004001\n",
            "\n",
            "[PASS] Target statistics computed\n"
          ]
        }
      ],
      "source": [
        "def check_target_statistics(\n",
        "    data_module: NQDataModule,\n",
        "    target_cols: list\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Check target statistics across splits.\n",
        "    \"\"\"\n",
        "    def get_stats(dataset, name, n_samples=1000):\n",
        "        targets_list = []\n",
        "        for i in range(min(n_samples, len(dataset))):\n",
        "            targets_list.append(dataset[i]['targets'].numpy())\n",
        "\n",
        "        targets = np.array(targets_list)\n",
        "\n",
        "        print(f\"\\n{name} target statistics:\")\n",
        "        for i, col in enumerate(target_cols):\n",
        "            print(f\"  {col}:\")\n",
        "            print(f\"    Mean: {targets[:, i].mean():.6f}\")\n",
        "            print(f\"    Std: {targets[:, i].std():.6f}\")\n",
        "\n",
        "    get_stats(data_module.train_dataset, \"Train\")\n",
        "    get_stats(data_module.val_dataset, \"Validation\")\n",
        "    get_stats(data_module.test_dataset, \"Test\")\n",
        "\n",
        "    print(\"\\n[PASS] Target statistics computed\")\n",
        "\n",
        "# Execute\n",
        "check_target_statistics(data_module, target_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "test_norm_consistency",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e3a929-f579-41b8-c9a3-1fce3c151f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature means for two different batches:\n",
            "  Batch 1: [2.8082022e-05 7.2043722e-06 4.0269093e-05 3.7512207e-05 1.0184747e-09]...\n",
            "  Batch 2: [-5.3882718e-06 -2.9709909e-05 -1.2825661e-05 -3.7584370e-05\n",
            " -1.0823839e-08]...\n",
            "\n",
            "Both should be close to zero (instance normalization per sample)\n",
            "\n",
            "[PASS] Instance normalization working correctly\n"
          ]
        }
      ],
      "source": [
        "def check_normalization_consistency(\n",
        "    data_module: NQDataModule\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Check instance normalization consistency.\n",
        "    \"\"\"\n",
        "    train_loader = data_module.train_dataloader()\n",
        "\n",
        "    batch1 = next(iter(train_loader))\n",
        "    batch2 = next(iter(train_loader))\n",
        "\n",
        "    # Extract valid positions\n",
        "    valid1 = batch1['features'][batch1['attention_mask']]\n",
        "    valid2 = batch2['features'][batch2['attention_mask']]\n",
        "\n",
        "    mean1 = valid1.mean(dim=0).numpy()\n",
        "    mean2 = valid2.mean(dim=0).numpy()\n",
        "\n",
        "    print(\"Feature means for two different batches:\")\n",
        "    print(f\"  Batch 1: {mean1[:5]}...\")\n",
        "    print(f\"  Batch 2: {mean2[:5]}...\")\n",
        "    print(f\"\\nBoth should be close to zero (instance normalization per sample)\")\n",
        "\n",
        "    assert np.allclose(mean1, 0, atol=0.1), \"Batch 1 not normalized\"\n",
        "    assert np.allclose(mean2, 0, atol=0.1), \"Batch 2 not normalized\"\n",
        "\n",
        "    print(\"\\n[PASS] Instance normalization working correctly\")\n",
        "\n",
        "# Execute\n",
        "check_normalization_consistency(data_module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "save_section"
      },
      "source": [
        "## 7. Save Splits (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "save_splits",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3edd12c-81e2-44a2-f9d9-b39591d042e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splits saved to /content/drive/MyDrive/Colab Notebooks/Transformers/FP/data/processed\n",
            "\n",
            "Split files saved to: /content/drive/MyDrive/Colab Notebooks/Transformers/FP/data/processed\n",
            "  - train_samples.parquet\n",
            "  - val_samples.parquet\n",
            "  - test_samples.parquet\n"
          ]
        }
      ],
      "source": [
        "def save_splits(\n",
        "    data_module: NQDataModule,\n",
        "    output_dir: Path\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Save train/val/test splits to parquet.\n",
        "    \"\"\"\n",
        "    data_module.save_splits(output_dir)\n",
        "\n",
        "    print(f\"\\nSplit files saved to: {output_dir}\")\n",
        "    print(\"  - train_samples.parquet\")\n",
        "    print(\"  - val_samples.parquet\")\n",
        "    print(\"  - test_samples.parquet\")\n",
        "\n",
        "# Execute (optional)\n",
        "save_splits(data_module, DATA_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary_section"
      },
      "source": [
        "## 8. Summary & Validation Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "print_summary",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f73983a-b1b8-40ce-fdfe-a9b1419403fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "PHASE 3 TESTING SUMMARY\n",
            "================================================================================\n",
            "\n",
            "[PASS] DataPreprocessor:\n",
            "  - Window creation with 24h lookback\n",
            "  - Padding to 288 max length\n",
            "  - Attention mask generation\n",
            "  - RevIN instance normalization\n",
            "  - Temporal info extraction\n",
            "  - Train/val/test splits with purge gaps\n",
            "  - Data leakage validation\n",
            "\n",
            "[PASS] NQFuturesDataset:\n",
            "  - PyTorch Dataset implementation\n",
            "  - Sample access (__getitem__)\n",
            "  - Tensor conversion\n",
            "  - Shape validation\n",
            "\n",
            "[PASS] NQDataModule:\n",
            "  - Data loading from parquet\n",
            "  - Split creation\n",
            "  - DataLoader initialization\n",
            "  - Batch loading\n",
            "  - GPU transfer\n",
            "\n",
            "[PASS] Integration:\n",
            "  - Full pipeline functionality\n",
            "  - Memory footprint acceptable\n",
            "  - GPU compatibility\n",
            "  - Data quality validated\n",
            "\n",
            "================================================================================\n",
            "ALL TESTS PASSED - PHASE 3 COMPLETE\n",
            "================================================================================\n",
            "\n",
            "Next steps:\n",
            "  Phase 4: Model Architecture Implementation\n",
            "  - Variable embedding module\n",
            "  - Positional encoding modules\n",
            "  - Temporal & variable attention\n",
            "  - Gated instance normalization\n",
            "  - Quantile output heads\n"
          ]
        }
      ],
      "source": [
        "def print_test_summary() -> None:\n",
        "    \"\"\"\n",
        "    Print comprehensive test summary.\n",
        "    \"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"PHASE 3 TESTING SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(\"\\n[PASS] DataPreprocessor:\")\n",
        "    print(\"  - Window creation with 24h lookback\")\n",
        "    print(\"  - Padding to 288 max length\")\n",
        "    print(\"  - Attention mask generation\")\n",
        "    print(\"  - RevIN instance normalization\")\n",
        "    print(\"  - Temporal info extraction\")\n",
        "    print(\"  - Train/val/test splits with purge gaps\")\n",
        "    print(\"  - Data leakage validation\")\n",
        "\n",
        "    print(\"\\n[PASS] NQFuturesDataset:\")\n",
        "    print(\"  - PyTorch Dataset implementation\")\n",
        "    print(\"  - Sample access (__getitem__)\")\n",
        "    print(\"  - Tensor conversion\")\n",
        "    print(\"  - Shape validation\")\n",
        "\n",
        "    print(\"\\n[PASS] NQDataModule:\")\n",
        "    print(\"  - Data loading from parquet\")\n",
        "    print(\"  - Split creation\")\n",
        "    print(\"  - DataLoader initialization\")\n",
        "    print(\"  - Batch loading\")\n",
        "    print(\"  - GPU transfer\")\n",
        "\n",
        "    print(\"\\n[PASS] Integration:\")\n",
        "    print(\"  - Full pipeline functionality\")\n",
        "    print(\"  - Memory footprint acceptable\")\n",
        "    print(\"  - GPU compatibility\")\n",
        "    print(\"  - Data quality validated\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ALL TESTS PASSED - PHASE 3 COMPLETE\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(\"\\nNext steps:\")\n",
        "    print(\"  Phase 4: Model Architecture Implementation\")\n",
        "    print(\"  - Variable embedding module\")\n",
        "    print(\"  - Positional encoding modules\")\n",
        "    print(\"  - Temporal & variable attention\")\n",
        "    print(\"  - Gated instance normalization\")\n",
        "    print(\"  - Quantile output heads\")\n",
        "\n",
        "# Execute\n",
        "print_test_summary()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}