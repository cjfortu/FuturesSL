{"cells":[{"cell_type":"markdown","metadata":{"id":"yi-_WicLCRrR"},"source":["# Dev Phase 1: Data Acquisition and Feature Engineering Tests\n","\n","This notebook provides comprehensive unit and integration tests for Dev Phase 1 modules:\n","- `src.data.acquisition`: Databento data download and validation\n","- `src.data.features`: Technical indicator computation (24 features)\n","\n","**Environment:** Google Colab with A100 GPU (80GB VRAM)\n","\n","**References:**\n","- grok-scientific.md Section 3.1: Feature specification (V=24)\n","- claude-engineering.md Section 3.1: Implementation details"]},{"cell_type":"markdown","metadata":{"id":"1B4gYD_DCRrV"},"source":["## 1. Environment Setup"]},{"cell_type":"code","source":["# Cell 1: Mount and Warning Suppression\n","# =====================================\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import warnings\n","import sys\n","\n","# Monkey-patch showwarning to filter jupyter_client's utcnow() deprecation\n","# Applied early to catch all subsequent thread emissions\n","_original_showwarning = warnings.showwarning\n","\n","def _filtered_showwarning(message, category, filename, lineno, file=None, line=None):\n","    \"\"\"Suppress jupyter_client datetime.utcnow() deprecation at display level.\"\"\"\n","    if category == DeprecationWarning and \"datetime.utcnow()\" in str(message):\n","        return\n","    _original_showwarning(message, category, filename, lineno, file, line)\n","\n","warnings.showwarning = _filtered_showwarning\n","print(\"Warning filter installed.\")\n","\n","PROJECT_ROOT = '/content/drive/MyDrive/Colab Notebooks/Transformers/FP'\n","\n","print(f\"Project root: {PROJECT_ROOT}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M2JIw_dxYtBx","executionInfo":{"status":"ok","timestamp":1765070471058,"user_tz":300,"elapsed":18967,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"}},"outputId":"0b4d3f63-b62a-4f98-adbe-6b962cc89e9d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Warning filter installed.\n","Project root: /content/drive/MyDrive/Colab Notebooks/Transformers/FP\n"]}]},{"cell_type":"code","source":["# Cell 1: Environment Setup\n","# =========================\n","\n","# Global deprecation suppression for async/threaded operations\n","# Must be set BEFORE any imports to propagate to all threads\n","import os\n","os.environ['PYTHONWARNINGS'] = 'ignore::DeprecationWarning'\n","\n","# Install dependencies\n","!pip install -q databento pandas numpy pyarrow tqdm scipy\n","\n","DATA_ROOT = '/content/drive/MyDrive/Colab Notebooks/Transformers/FP/data'\n","os.makedirs(f'{DATA_ROOT}/raw', exist_ok=True)\n","os.makedirs(f'{DATA_ROOT}/processed', exist_ok=True)\n","os.makedirs(f'{DATA_ROOT}/metadata', exist_ok=True)\n","\n","print(\"Environment ready!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wXPfcE5wSwFK","executionInfo":{"status":"ok","timestamp":1765070476592,"user_tz":300,"elapsed":5501,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"}},"outputId":"c7750033-555a-4bcc-fc19-a7022ff84f65"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.1/75.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.9/85.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m174.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/242.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/221.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.6/221.6 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/377.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hEnvironment ready!\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1284,"status":"ok","timestamp":1765070477896,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"0q97yyDyCRrY"},"outputs":[],"source":["# Install dependencies\n","!pip install -q pandas numpy pyarrow scipy\n","\n","# Note: databento is only needed for actual data download\n","# Tests use synthetic data, so databento installation is optional\n","# !pip install -q databento"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2991,"status":"ok","timestamp":1765070480900,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"l86SsYpSCRrZ","outputId":"c415cc17-efcf-467d-941f-fb42a52f27a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully imported FeatureEngineer\n","Number of features: 24\n","Number of feature groups: 6\n"]}],"source":["# Add source to path\n","import sys\n","from pathlib import Path\n","\n","src_path = Path(PROJECT_ROOT) / 'src'\n","if str(src_path) not in sys.path:\n","    sys.path.insert(0, str(src_path.parent))\n","\n","# Verify import\n","from src.data.features import FeatureEngineer, FEATURE_COLUMNS, FEATURE_GROUPS\n","print(f\"Successfully imported FeatureEngineer\")\n","print(f\"Number of features: {len(FEATURE_COLUMNS)}\")\n","print(f\"Number of feature groups: {len(FEATURE_GROUPS)}\")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1765070480954,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"ybY88DajCRra"},"outputs":[],"source":["# Cell 4: Standard Imports for Testing\n","# =====================================\n","import unittest\n","import logging\n","from datetime import datetime, timedelta\n","from typing import Dict, List, Tuple\n","\n","import numpy as np\n","import pandas as pd\n","\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)"]},{"cell_type":"markdown","metadata":{"id":"hQoJk6k0CRrb"},"source":["## 2. Synthetic Data Generation\n","\n","Generate realistic NQ futures data for testing without requiring Databento API access."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":310},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1765070481007,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"EFum82aRCRrd","outputId":"d9ecc39d-b3a3-41c1-e47c-c580447b0951"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generating synthetic OHLCV data...\n","Generated 10,000 bars\n","Date range: 2023-01-03 18:00:00 to 2023-01-13 00:38:00\n","Price range: 14803.83 to 15338.44\n","\n","Sample data:\n"]},{"output_type":"execute_result","data":{"text/plain":["            timestamp          open          high           low         close  \\\n","0 2023-01-03 18:00:00  15000.539959  15004.611332  15000.539959  15001.490216   \n","1 2023-01-03 18:01:00  15001.457668  15001.457668  14999.624539  15001.075388   \n","2 2023-01-03 18:02:00  15001.075388  15004.165882  15000.580874  15003.018719   \n","3 2023-01-03 18:03:00  15007.111325  15007.774168  15007.111325  15007.589424   \n","4 2023-01-03 18:04:00  15007.589424  15009.642047  15002.455678  15006.886625   \n","\n","   volume  \n","0     244  \n","1    2598  \n","2     723  \n","3     656  \n","4    5547  "],"text/html":["\n","  <div id=\"df-e7dc2242-7f31-48a4-8862-ff30c46f20bf\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>timestamp</th>\n","      <th>open</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>close</th>\n","      <th>volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2023-01-03 18:00:00</td>\n","      <td>15000.539959</td>\n","      <td>15004.611332</td>\n","      <td>15000.539959</td>\n","      <td>15001.490216</td>\n","      <td>244</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2023-01-03 18:01:00</td>\n","      <td>15001.457668</td>\n","      <td>15001.457668</td>\n","      <td>14999.624539</td>\n","      <td>15001.075388</td>\n","      <td>2598</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2023-01-03 18:02:00</td>\n","      <td>15001.075388</td>\n","      <td>15004.165882</td>\n","      <td>15000.580874</td>\n","      <td>15003.018719</td>\n","      <td>723</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2023-01-03 18:03:00</td>\n","      <td>15007.111325</td>\n","      <td>15007.774168</td>\n","      <td>15007.111325</td>\n","      <td>15007.589424</td>\n","      <td>656</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2023-01-03 18:04:00</td>\n","      <td>15007.589424</td>\n","      <td>15009.642047</td>\n","      <td>15002.455678</td>\n","      <td>15006.886625</td>\n","      <td>5547</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7dc2242-7f31-48a4-8862-ff30c46f20bf')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e7dc2242-7f31-48a4-8862-ff30c46f20bf button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e7dc2242-7f31-48a4-8862-ff30c46f20bf');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-2b2aedab-96b8-4411-91b4-5ce3799c46f1\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2b2aedab-96b8-4411-91b4-5ce3799c46f1')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-2b2aedab-96b8-4411-91b4-5ce3799c46f1 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"synthetic_df","summary":"{\n  \"name\": \"synthetic_df\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2023-01-03 18:00:00\",\n        \"max\": \"2023-01-13 00:38:00\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"2023-01-10 07:11:00\",\n          \"2023-01-09 04:03:00\",\n          \"2023-01-04 23:51:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 143.47574960928213,\n        \"min\": 14804.466910246805,\n        \"max\": 15337.239095659834,\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          14963.604481912174,\n          15093.988870725523,\n          15267.005257975523\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 143.54700068446627,\n        \"min\": 14805.142775157949,\n        \"max\": 15341.326872411919,\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          14965.084665724333,\n          15093.988870725523,\n          15272.865060605216\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 143.47949021460084,\n        \"min\": 14801.299762337057,\n        \"max\": 15337.239095659834,\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          14963.604481912174,\n          15089.478057751692,\n          15257.930273287493\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 143.49024670095045,\n        \"min\": 14803.829994920525,\n        \"max\": 15338.441357301646,\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          14964.048432066193,\n          15091.947194669598,\n          15265.938690960347\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1009,\n        \"min\": 0,\n        \"max\": 10488,\n        \"num_unique_values\": 2927,\n        \"samples\": [\n          2560,\n          1957,\n          1552\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}],"source":["def generate_synthetic_ohlcv(\n","    n_bars: int = 10000,\n","    start_price: float = 15000.0,\n","    volatility: float = 0.0002,\n","    start_date: str = \"2023-01-03 18:00:00\",\n","    include_gaps: bool = True,\n","    seed: int = 42\n",") -> pd.DataFrame:\n","    \"\"\"\n","    Generate synthetic NQ futures OHLCV data for testing.\n","\n","    Creates realistic price movements with:\n","    - Geometric Brownian Motion for price evolution\n","    - Realistic OHLC relationships\n","    - Volume with intraday patterns\n","    - Optional time gaps (market closures)\n","\n","    Args:\n","        n_bars: Number of 1-minute bars to generate.\n","        start_price: Initial NQ price level.\n","        volatility: Per-bar volatility (standard deviation of returns).\n","        start_date: Starting timestamp.\n","        include_gaps: Whether to include realistic time gaps.\n","        seed: Random seed for reproducibility.\n","\n","    Returns:\n","        DataFrame with columns: [timestamp, open, high, low, close, volume]\n","    \"\"\"\n","    np.random.seed(seed)\n","\n","    # Generate returns using GBM\n","    returns = np.random.normal(0, volatility, n_bars)\n","\n","    # Generate close prices\n","    log_prices = np.log(start_price) + np.cumsum(returns)\n","    close = np.exp(log_prices)\n","\n","    # Generate OHLC from close\n","    # High-low range varies with volatility\n","    hl_range = np.abs(np.random.normal(0, volatility * 2, n_bars)) * close\n","\n","    # Close location within bar (random uniform)\n","    close_loc = np.random.uniform(0.2, 0.8, n_bars)\n","\n","    low = close - close_loc * hl_range\n","    high = low + hl_range\n","\n","    # Open is previous close with small gap\n","    open_prices = np.roll(close, 1)\n","    open_prices[0] = start_price\n","\n","    # Adjust open to be within bar range\n","    open_prices = np.clip(open_prices, low, high)\n","\n","    # Generate volume with intraday pattern\n","    base_volume = 1000\n","    volume_noise = np.random.exponential(base_volume, n_bars)\n","\n","    # Generate timestamps\n","    start_dt = pd.Timestamp(start_date)\n","    timestamps = []\n","    current_ts = start_dt\n","\n","    for i in range(n_bars):\n","        timestamps.append(current_ts)\n","\n","        # Add time gap logic\n","        if include_gaps:\n","            # Skip weekends and add session gaps\n","            next_ts = current_ts + timedelta(minutes=1)\n","\n","            # Friday 17:00 -> Sunday 18:00 (weekend gap)\n","            if current_ts.dayofweek == 4 and current_ts.hour >= 17:\n","                next_ts = current_ts + timedelta(days=2, hours=1)\n","            # Daily maintenance break: 17:00-18:00 ET\n","            elif current_ts.hour == 16 and current_ts.minute == 59:\n","                next_ts = current_ts + timedelta(hours=1, minutes=1)\n","\n","            current_ts = next_ts\n","        else:\n","            current_ts += timedelta(minutes=1)\n","\n","    df = pd.DataFrame({\n","        'timestamp': timestamps,\n","        'open': open_prices,\n","        'high': high,\n","        'low': low,\n","        'close': close,\n","        'volume': volume_noise.astype(np.int64)\n","    })\n","\n","    return df\n","\n","# Generate test data\n","print(\"Generating synthetic OHLCV data...\")\n","synthetic_df = generate_synthetic_ohlcv(n_bars=10000)\n","print(f\"Generated {len(synthetic_df):,} bars\")\n","print(f\"Date range: {synthetic_df['timestamp'].min()} to {synthetic_df['timestamp'].max()}\")\n","print(f\"Price range: {synthetic_df['close'].min():.2f} to {synthetic_df['close'].max():.2f}\")\n","print(f\"\\nSample data:\")\n","synthetic_df.head()"]},{"cell_type":"markdown","metadata":{"id":"rXOyNw5VCRrf"},"source":["## 3. Unit Tests: Feature Engineering"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1765070481044,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"e_vzeBdOCRrh","outputId":"55404b6a-bead-4cc6-f67a-e0fe9b93dc2b"},"outputs":[{"output_type":"stream","name":"stderr","text":["test_custom_initialization (__main__.TestFeatureEngineerInit.test_custom_initialization)\n","Verify custom parameters are applied. ... ok\n","test_default_initialization (__main__.TestFeatureEngineerInit.test_default_initialization)\n","Verify default parameters are set correctly. ... ok\n","test_warmup_period_calculation (__main__.TestFeatureEngineerInit.test_warmup_period_calculation)\n","Verify warmup period is correctly computed. ... ok\n","\n","----------------------------------------------------------------------\n","Ran 3 tests in 0.001s\n","\n","OK\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tests run: 3, Failures: 0, Errors: 0\n"]}],"source":["class TestFeatureEngineerInit(unittest.TestCase):\n","    \"\"\"Test FeatureEngineer initialization and configuration.\"\"\"\n","\n","    def test_default_initialization(self):\n","        \"\"\"Verify default parameters are set correctly.\"\"\"\n","        fe = FeatureEngineer()\n","\n","        self.assertEqual(fe.rsi_period, 14)\n","        self.assertEqual(fe.atr_period, 14)\n","        self.assertEqual(fe.bb_period, 20)\n","        self.assertEqual(fe.bb_std, 2.0)\n","        self.assertEqual(fe.macd_fast, 12)\n","        self.assertEqual(fe.macd_slow, 26)\n","        self.assertEqual(fe.macd_signal, 9)\n","        self.assertEqual(fe.sma_periods, [20, 50, 200])\n","        self.assertEqual(fe.rth_open_hour, 9)\n","        self.assertEqual(fe.rth_open_minute, 30)\n","\n","    def test_custom_initialization(self):\n","        \"\"\"Verify custom parameters are applied.\"\"\"\n","        fe = FeatureEngineer(\n","            rsi_period=10,\n","            sma_periods=[10, 20],\n","            rth_open_hour=8\n","        )\n","\n","        self.assertEqual(fe.rsi_period, 10)\n","        self.assertEqual(fe.sma_periods, [10, 20])\n","        self.assertEqual(fe.rth_open_hour, 8)\n","\n","    def test_warmup_period_calculation(self):\n","        \"\"\"Verify warmup period is correctly computed.\"\"\"\n","        fe = FeatureEngineer()\n","\n","        # Warmup should be at least max(MACD, SMA200, ADX*2)\n","        expected_min = max(26 + 9, 200, 14 * 2, 20)\n","        self.assertGreaterEqual(fe.warmup_period, expected_min)\n","\n","# Run tests\n","suite = unittest.TestLoader().loadTestsFromTestCase(TestFeatureEngineerInit)\n","runner = unittest.TextTestRunner(verbosity=2)\n","result = runner.run(suite)\n","print(f\"\\nTests run: {result.testsRun}, Failures: {len(result.failures)}, Errors: {len(result.errors)}\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1765070481088,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"82X_OcGhCRri","outputId":"fb638866-6dbb-45b6-9075-eb30b22052e2"},"outputs":[{"output_type":"stream","name":"stderr","text":["test_feature_count (__main__.TestFeatureColumns.test_feature_count)\n","Verify exactly 24 features per grok-scientific.md Section 3.1. ... ok\n","test_feature_group_sizes (__main__.TestFeatureColumns.test_feature_group_sizes)\n","Verify feature group sizes per grok-scientific.md. ... ok\n","test_feature_groups_coverage (__main__.TestFeatureColumns.test_feature_groups_coverage)\n","Verify all features belong to exactly one group. ... ok\n","test_flow_group_features (__main__.TestFeatureColumns.test_flow_group_features)\n","Verify flow group contains MFI and time_gap. ... ok\n","test_price_group_features (__main__.TestFeatureColumns.test_price_group_features)\n","Verify price group contains expected features. ... ok\n","\n","----------------------------------------------------------------------\n","Ran 5 tests in 0.002s\n","\n","OK\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tests run: 5, Failures: 0, Errors: 0\n"]}],"source":["class TestFeatureColumns(unittest.TestCase):\n","    \"\"\"Test feature column specification per grok-scientific.md.\"\"\"\n","\n","    def test_feature_count(self):\n","        \"\"\"Verify exactly 24 features per grok-scientific.md Section 3.1.\"\"\"\n","        self.assertEqual(len(FEATURE_COLUMNS), 24)\n","\n","    def test_feature_groups_coverage(self):\n","        \"\"\"Verify all features belong to exactly one group.\"\"\"\n","        all_grouped = []\n","        for group_features in FEATURE_GROUPS.values():\n","            all_grouped.extend(group_features)\n","\n","        # Check no duplicates\n","        self.assertEqual(len(all_grouped), len(set(all_grouped)))\n","\n","        # Check coverage\n","        self.assertEqual(set(all_grouped), set(FEATURE_COLUMNS))\n","\n","    def test_feature_group_sizes(self):\n","        \"\"\"Verify feature group sizes per grok-scientific.md.\"\"\"\n","        expected_sizes = {\n","            'price': 4,       # F_P\n","            'volume': 3,      # F_V\n","            'trend': 5,       # F_T\n","            'momentum': 6,    # F_M\n","            'volatility': 4,  # F_σ\n","            'flow': 2,        # F_VW + temporal\n","        }\n","\n","        for group, expected_size in expected_sizes.items():\n","            actual_size = len(FEATURE_GROUPS[group])\n","            self.assertEqual(\n","                actual_size, expected_size,\n","                f\"Group '{group}' has {actual_size} features, expected {expected_size}\"\n","            )\n","\n","    def test_price_group_features(self):\n","        \"\"\"Verify price group contains expected features.\"\"\"\n","        expected = {'log_return', 'hl_range', 'close_location', 'open_return'}\n","        self.assertEqual(set(FEATURE_GROUPS['price']), expected)\n","\n","    def test_flow_group_features(self):\n","        \"\"\"Verify flow group contains MFI and time_gap.\"\"\"\n","        expected = {'mfi_norm', 'time_gap'}\n","        self.assertEqual(set(FEATURE_GROUPS['flow']), expected)\n","\n","# Run tests\n","suite = unittest.TestLoader().loadTestsFromTestCase(TestFeatureColumns)\n","runner = unittest.TextTestRunner(verbosity=2)\n","result = runner.run(suite)\n","print(f\"\\nTests run: {result.testsRun}, Failures: {len(result.failures)}, Errors: {len(result.errors)}\")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1765070481127,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"FpHWzWuXCRrj","outputId":"c3ab87ff-b334-48b0-fbf6-79a401907787"},"outputs":[{"output_type":"stream","name":"stderr","text":["test_close_location_bounds (__main__.TestPriceDynamicsFeatures.test_close_location_bounds)\n","Verify close_location is in [0, 1]. ... ok\n","test_hl_range_positive (__main__.TestPriceDynamicsFeatures.test_hl_range_positive)\n","Verify hl_range is always non-negative. ... ok\n","test_log_return_calculation (__main__.TestPriceDynamicsFeatures.test_log_return_calculation)\n","Verify log_return = ln(close_t / close_{t-1}). ... ok\n","test_log_return_stationarity (__main__.TestPriceDynamicsFeatures.test_log_return_stationarity)\n","Verify log returns have near-zero mean (stationarity). ... ok\n","test_open_return_calculation (__main__.TestPriceDynamicsFeatures.test_open_return_calculation)\n","Verify open_return = ln(close / open). ... ok\n","\n","----------------------------------------------------------------------\n","Ran 5 tests in 0.057s\n","\n","OK\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tests run: 5, Failures: 0, Errors: 0\n"]}],"source":["class TestPriceDynamicsFeatures(unittest.TestCase):\n","    \"\"\"Test F_P: Price dynamics feature computation.\"\"\"\n","\n","    @classmethod\n","    def setUpClass(cls):\n","        \"\"\"Generate test data once for all tests.\"\"\"\n","        cls.df = generate_synthetic_ohlcv(n_bars=1000, seed=123)\n","        cls.fe = FeatureEngineer()\n","        cls.features = cls.fe.compute_all_features(cls.df)\n","\n","    def test_log_return_calculation(self):\n","        \"\"\"Verify log_return = ln(close_t / close_{t-1}).\"\"\"\n","        expected = np.log(self.df['close'] / self.df['close'].shift(1))\n","        actual = self.features['log_return']\n","\n","        # Skip first bar (NaN)\n","        np.testing.assert_array_almost_equal(\n","            actual.values[1:], expected.values[1:], decimal=10\n","        )\n","\n","    def test_log_return_stationarity(self):\n","        \"\"\"Verify log returns have near-zero mean (stationarity).\"\"\"\n","        log_returns = self.features['log_return'].dropna()\n","        self.assertAlmostEqual(log_returns.mean(), 0.0, places=3)\n","\n","    def test_hl_range_positive(self):\n","        \"\"\"Verify hl_range is always non-negative.\"\"\"\n","        hl_range = self.features['hl_range']\n","        self.assertTrue((hl_range >= 0).all())\n","\n","    def test_close_location_bounds(self):\n","        \"\"\"Verify close_location is in [0, 1].\"\"\"\n","        close_loc = self.features['close_location']\n","        self.assertTrue((close_loc >= 0).all())\n","        self.assertTrue((close_loc <= 1).all())\n","\n","    def test_open_return_calculation(self):\n","        \"\"\"Verify open_return = ln(close / open).\"\"\"\n","        expected = np.log(self.df['close'] / self.df['open'])\n","        actual = self.features['open_return']\n","\n","        np.testing.assert_array_almost_equal(\n","            actual.values, expected.values, decimal=10\n","        )\n","\n","# Run tests\n","suite = unittest.TestLoader().loadTestsFromTestCase(TestPriceDynamicsFeatures)\n","runner = unittest.TextTestRunner(verbosity=2)\n","result = runner.run(suite)\n","print(f\"\\nTests run: {result.testsRun}, Failures: {len(result.failures)}, Errors: {len(result.errors)}\")"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52,"status":"ok","timestamp":1765070481198,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"OMavL5MdCRrk","outputId":"ce4c50fa-b1ad-46cb-c67b-6cb14217e7c8"},"outputs":[{"output_type":"stream","name":"stderr","text":["test_dollar_volume_calculation (__main__.TestVolumeFeatures.test_dollar_volume_calculation)\n","Verify dollar_volume = log1p(close * volume). ... ok\n","test_log_volume_delta_calculation (__main__.TestVolumeFeatures.test_log_volume_delta_calculation)\n","Verify log_volume_delta is difference of log volumes. ... ok\n","test_log_volume_handles_zero (__main__.TestVolumeFeatures.test_log_volume_handles_zero)\n","Verify log_volume uses log1p to handle zero volume. ... ok\n","\n","----------------------------------------------------------------------\n","Ran 3 tests in 0.049s\n","\n","OK\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tests run: 3, Failures: 0, Errors: 0\n"]}],"source":["class TestVolumeFeatures(unittest.TestCase):\n","    \"\"\"Test F_V: Volume feature computation.\"\"\"\n","\n","    @classmethod\n","    def setUpClass(cls):\n","        cls.df = generate_synthetic_ohlcv(n_bars=1000, seed=456)\n","        cls.fe = FeatureEngineer()\n","        cls.features = cls.fe.compute_all_features(cls.df)\n","\n","    def test_log_volume_handles_zero(self):\n","        \"\"\"Verify log_volume uses log1p to handle zero volume.\"\"\"\n","        # Create data with zero volume\n","        df = self.df.copy()\n","        df.loc[100, 'volume'] = 0\n","\n","        fe = FeatureEngineer()\n","        features = fe.compute_all_features(df)\n","\n","        # log1p(0) = 0, so zero volume should give 0\n","        self.assertEqual(features.loc[100, 'log_volume'], 0.0)\n","\n","    def test_log_volume_delta_calculation(self):\n","        \"\"\"Verify log_volume_delta is difference of log volumes.\"\"\"\n","        log_vol = self.features['log_volume']\n","        expected_delta = log_vol - log_vol.shift(1)\n","        actual_delta = self.features['log_volume_delta']\n","\n","        np.testing.assert_array_almost_equal(\n","            actual_delta.values[1:], expected_delta.values[1:], decimal=10\n","        )\n","\n","    def test_dollar_volume_calculation(self):\n","        \"\"\"Verify dollar_volume = log1p(close * volume).\"\"\"\n","        expected = np.log1p(self.df['close'] * self.df['volume'])\n","        actual = self.features['dollar_volume']\n","\n","        np.testing.assert_array_almost_equal(\n","            actual.values, expected.values, decimal=10\n","        )\n","\n","# Run tests\n","suite = unittest.TestLoader().loadTestsFromTestCase(TestVolumeFeatures)\n","runner = unittest.TextTestRunner(verbosity=2)\n","result = runner.run(suite)\n","print(f\"\\nTests run: {result.testsRun}, Failures: {len(result.failures)}, Errors: {len(result.errors)}\")"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1765070481231,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"zYOaYu94CRrk","outputId":"a9e26885-f0c1-47b8-de99-48c2974a5303"},"outputs":[{"output_type":"stream","name":"stderr","text":["test_dmi_components_bounds (__main__.TestMomentumFeatures.test_dmi_components_bounds)\n","Verify +DI, -DI, ADX are in [0, 1] after normalization. ... ok\n","test_roc_calculation (__main__.TestMomentumFeatures.test_roc_calculation)\n","Verify roc_norm = (close_t / close_{t-10}) - 1. ... ok\n","test_rsi_norm_bounds (__main__.TestMomentumFeatures.test_rsi_norm_bounds)\n","Verify rsi_norm is in [-1, 1] after warmup. ... ok\n","test_rsi_norm_transformation (__main__.TestMomentumFeatures.test_rsi_norm_transformation)\n","Verify rsi_norm = (RSI - 50) / 50. ... ok\n","\n","----------------------------------------------------------------------\n","Ran 4 tests in 0.042s\n","\n","OK\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tests run: 4, Failures: 0, Errors: 0\n"]}],"source":["class TestMomentumFeatures(unittest.TestCase):\n","    \"\"\"Test F_M: Momentum feature computation.\"\"\"\n","\n","    @classmethod\n","    def setUpClass(cls):\n","        cls.df = generate_synthetic_ohlcv(n_bars=2000, seed=789)\n","        cls.fe = FeatureEngineer()\n","        cls.features = cls.fe.compute_all_features(cls.df)\n","\n","    def test_rsi_norm_bounds(self):\n","        \"\"\"Verify rsi_norm is in [-1, 1] after warmup.\"\"\"\n","        rsi_norm = self.features['rsi_norm'].dropna()\n","\n","        self.assertTrue((rsi_norm >= -1).all())\n","        self.assertTrue((rsi_norm <= 1).all())\n","\n","    def test_rsi_norm_transformation(self):\n","        \"\"\"Verify rsi_norm = (RSI - 50) / 50.\"\"\"\n","        # RSI of 50 should give 0\n","        # RSI of 100 should give 1\n","        # RSI of 0 should give -1\n","        rsi_norm = self.features['rsi_norm'].dropna()\n","\n","        # Mean should be close to 0 for random walk\n","        self.assertAlmostEqual(rsi_norm.mean(), 0.0, places=1)\n","\n","    def test_dmi_components_bounds(self):\n","        \"\"\"Verify +DI, -DI, ADX are in [0, 1] after normalization.\"\"\"\n","        for col in ['plus_di', 'minus_di', 'adx']:\n","            values = self.features[col].dropna()\n","            self.assertTrue(\n","                (values >= 0).all(),\n","                f\"{col} has negative values\"\n","            )\n","            self.assertTrue(\n","                (values <= 1.5).all(),  # Allow slight overshoot\n","                f\"{col} has values > 1.5\"\n","            )\n","\n","    def test_roc_calculation(self):\n","        \"\"\"Verify roc_norm = (close_t / close_{t-10}) - 1.\"\"\"\n","        expected = self.df['close'] / self.df['close'].shift(10) - 1\n","        actual = self.features['roc_norm']\n","\n","        # Skip warmup period\n","        np.testing.assert_array_almost_equal(\n","            actual.values[10:], expected.values[10:], decimal=10\n","        )\n","\n","# Run tests\n","suite = unittest.TestLoader().loadTestsFromTestCase(TestMomentumFeatures)\n","runner = unittest.TextTestRunner(verbosity=2)\n","result = runner.run(suite)\n","print(f\"\\nTests run: {result.testsRun}, Failures: {len(result.failures)}, Errors: {len(result.errors)}\")"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1765070481269,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"xO-k3NMKCRrl","outputId":"bd3727ef-68b9-46d0-ceef-bfe9c395fba3"},"outputs":[{"output_type":"stream","name":"stderr","text":["test_atr_norm_positive (__main__.TestVolatilityFeatures.test_atr_norm_positive)\n","Verify ATR is always positive. ... ok\n","test_bb_bandwidth_positive (__main__.TestVolatilityFeatures.test_bb_bandwidth_positive)\n","Verify Bollinger bandwidth is positive. ... ok\n","test_bb_pct_b_bounds (__main__.TestVolatilityFeatures.test_bb_pct_b_bounds)\n","Verify Bollinger %B is roughly in [0, 1] for normal prices. ... ok\n","test_realized_vol_annualization (__main__.TestVolatilityFeatures.test_realized_vol_annualization)\n","Verify realized vol is annualized (reasonable magnitude). ... ok\n","test_realized_vol_positive (__main__.TestVolatilityFeatures.test_realized_vol_positive)\n","Verify realized volatility is non-negative. ... ok\n","\n","----------------------------------------------------------------------\n","Ran 5 tests in 0.041s\n","\n","OK\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tests run: 5, Failures: 0, Errors: 0\n"]}],"source":["class TestVolatilityFeatures(unittest.TestCase):\n","    \"\"\"Test F_σ: Volatility feature computation.\"\"\"\n","\n","    @classmethod\n","    def setUpClass(cls):\n","        cls.df = generate_synthetic_ohlcv(n_bars=2000, seed=321)\n","        cls.fe = FeatureEngineer()\n","        cls.features = cls.fe.compute_all_features(cls.df)\n","\n","    def test_atr_norm_positive(self):\n","        \"\"\"Verify ATR is always positive.\"\"\"\n","        atr = self.features['atr_norm'].dropna()\n","        self.assertTrue((atr >= 0).all())\n","\n","    def test_bb_pct_b_bounds(self):\n","        \"\"\"Verify Bollinger %B is roughly in [0, 1] for normal prices.\"\"\"\n","        bb_pct_b = self.features['bb_pct_b'].dropna()\n","\n","        # Most values should be in [0, 1] but extremes can exceed\n","        in_range = ((bb_pct_b >= -0.5) & (bb_pct_b <= 1.5)).mean()\n","        self.assertGreater(in_range, 0.95)\n","\n","    def test_bb_bandwidth_positive(self):\n","        \"\"\"Verify Bollinger bandwidth is positive.\"\"\"\n","        bandwidth = self.features['bb_bandwidth'].dropna()\n","        self.assertTrue((bandwidth >= 0).all())\n","\n","    def test_realized_vol_positive(self):\n","        \"\"\"Verify realized volatility is non-negative.\"\"\"\n","        realized_vol = self.features['realized_vol'].dropna()\n","        self.assertTrue((realized_vol >= 0).all())\n","\n","    def test_realized_vol_annualization(self):\n","        \"\"\"Verify realized vol is annualized (reasonable magnitude).\"\"\"\n","        # For typical market conditions, annualized vol should be 0.1-0.5 (10-50%)\n","        realized_vol = self.features['realized_vol'].dropna()\n","        mean_vol = realized_vol.mean()\n","\n","        # Synthetic data vol should be in reasonable range\n","        self.assertGreater(mean_vol, 0.01)  # At least 1%\n","        self.assertLess(mean_vol, 2.0)       # Less than 200%\n","\n","# Run tests\n","suite = unittest.TestLoader().loadTestsFromTestCase(TestVolatilityFeatures)\n","runner = unittest.TextTestRunner(verbosity=2)\n","result = runner.run(suite)\n","print(f\"\\nTests run: {result.testsRun}, Failures: {len(result.failures)}, Errors: {len(result.errors)}\")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1765070481296,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"oBFY8iYWCRrm","outputId":"810b35a3-8508-4af0-f68d-651772880c41"},"outputs":[{"output_type":"stream","name":"stderr","text":["test_vwap_deviation_bounded (__main__.TestVWAPFeature.test_vwap_deviation_bounded)\n","Verify VWAP deviation is reasonably bounded. ... ok\n","test_vwap_session_reset (__main__.TestVWAPFeature.test_vwap_session_reset)\n","Verify VWAP resets at RTH open (09:30 ET). ... ok\n","\n","----------------------------------------------------------------------\n","Ran 2 tests in 0.047s\n","\n","OK\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tests run: 2, Failures: 0, Errors: 0\n"]}],"source":["class TestVWAPFeature(unittest.TestCase):\n","    \"\"\"Test VWAP deviation with RTH session reset.\"\"\"\n","\n","    def test_vwap_session_reset(self):\n","        \"\"\"Verify VWAP resets at RTH open (09:30 ET).\"\"\"\n","        # Create data spanning multiple sessions\n","        # Start just before RTH open\n","        df = generate_synthetic_ohlcv(\n","            n_bars=500,\n","            start_date=\"2023-01-03 09:00:00\",\n","            include_gaps=False,\n","            seed=111\n","        )\n","\n","        fe = FeatureEngineer()\n","        features = fe.compute_all_features(df)\n","\n","        # VWAP deviation should exist\n","        self.assertIn('vwap_deviation', features.columns)\n","\n","        # Check for session boundaries\n","        # At 09:30, VWAP resets, so deviation should be small\n","        rth_start_mask = (\n","            (df['timestamp'].dt.hour == 9) &\n","            (df['timestamp'].dt.minute == 30)\n","        )\n","\n","        if rth_start_mask.any():\n","            # At session start, price ≈ VWAP, so deviation should be small\n","            vwap_at_rth = features.loc[rth_start_mask, 'vwap_deviation'].abs()\n","            # First bar of session: VWAP = typical price, deviation small\n","            self.assertTrue((vwap_at_rth < 0.01).all())\n","\n","    def test_vwap_deviation_bounded(self):\n","        \"\"\"Verify VWAP deviation is reasonably bounded.\"\"\"\n","        df = generate_synthetic_ohlcv(n_bars=1000, seed=222)\n","\n","        fe = FeatureEngineer()\n","        features = fe.compute_all_features(df)\n","\n","        vwap_dev = features['vwap_deviation'].dropna()\n","\n","        # Deviation should typically be within ±5%\n","        self.assertTrue((vwap_dev.abs() < 0.1).mean() > 0.95)\n","\n","# Run tests\n","suite = unittest.TestLoader().loadTestsFromTestCase(TestVWAPFeature)\n","runner = unittest.TextTestRunner(verbosity=2)\n","result = runner.run(suite)\n","print(f\"\\nTests run: {result.testsRun}, Failures: {len(result.failures)}, Errors: {len(result.errors)}\")"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1765070481345,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"x3G1c0R5CRrm","outputId":"eb5f2e48-3ead-4799-ed07-c28b5ab2a59e"},"outputs":[{"output_type":"stream","name":"stderr","text":["test_mfi_norm_bounds (__main__.TestMFIFeature.test_mfi_norm_bounds)\n","Verify mfi_norm is in [-1, 1]. ... ok\n","test_mfi_uses_typical_price_direction (__main__.TestMFIFeature.test_mfi_uses_typical_price_direction)\n","Verify MFI uses typical price direction, not close price direction. ... ok\n","\n","----------------------------------------------------------------------\n","Ran 2 tests in 0.050s\n","\n","OK\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tests run: 2, Failures: 0, Errors: 0\n"]}],"source":["class TestMFIFeature(unittest.TestCase):\n","    \"\"\"Test MFI (Money Flow Index) feature computation.\"\"\"\n","\n","    def test_mfi_uses_typical_price_direction(self):\n","        \"\"\"\n","        Verify MFI uses typical price direction, not close price direction.\n","\n","        Per gemini-research.md Section 4.2:\n","        'MFI (Money Flow Index): A volume-weighted RSI.'\n","\n","        Standard MFI uses typical price = (H + L + C) / 3 for flow direction.\n","        \"\"\"\n","        # Create controlled test case\n","        df = pd.DataFrame({\n","            'timestamp': pd.date_range('2023-01-01', periods=100, freq='1min'),\n","            'open': [100.0] * 100,\n","            'high': [101.0] * 100,\n","            'low': [99.0] * 100,\n","            'close': [100.0] * 100,  # Close unchanged throughout\n","            'volume': [1000] * 100\n","        })\n","\n","        # Modify second half to have INCREASING typical price\n","        # but CONSTANT close price.\n","        # Increment high/low at each step to create positive momentum.\n","        for i in range(50, 100):\n","            increment = (i - 50) * 0.1\n","            df.loc[i, 'high'] = 101.0 + increment\n","            df.loc[i, 'low'] = 99.0 + increment\n","            # Close remains 100.0\n","            #\n","            # Mathematical proof:\n","            # TP_prev = (H + L + 100) / 3\n","            # TP_curr = (H+inc + L+inc + 100) / 3\n","            # Delta TP > 0 → Positive Money Flow\n","\n","        fe = FeatureEngineer(mfi_period=14)\n","        features = fe.compute_all_features(df)\n","\n","        # Early period: Flat prices → No flow → MFI ≈ 0 → Norm ≈ -1.0\n","        mfi_early = features.loc[30:49, 'mfi_norm'].mean()\n","\n","        # Late period: Rising High/Low → Positive flow → MFI ≈ 100 → Norm ≈ 1.0\n","        mfi_late = features.loc[70:99, 'mfi_norm'].mean()\n","\n","        # MFI should be significantly higher in second half,\n","        # verifying it reacted to High/Low changes despite flat Close\n","        self.assertGreater(mfi_late, mfi_early,\n","                          f\"Late MFI ({mfi_late:.4f}) should exceed early ({mfi_early:.4f})\")\n","        self.assertAlmostEqual(mfi_early, -1.0, places=1,\n","                              msg=f\"Early MFI should be near -1 (no flow), got {mfi_early:.4f}\")\n","        self.assertGreater(mfi_late, 0.9,\n","                          msg=f\"Late MFI should be near 1.0 (max positive flow), got {mfi_late:.4f}\")\n","\n","    def test_mfi_norm_bounds(self):\n","        \"\"\"Verify mfi_norm is in [-1, 1].\"\"\"\n","        df = generate_synthetic_ohlcv(n_bars=1000, seed=333)\n","\n","        fe = FeatureEngineer()\n","        features = fe.compute_all_features(df)\n","\n","        mfi_norm = features['mfi_norm'].dropna()\n","\n","        self.assertTrue((mfi_norm >= -1).all())\n","        self.assertTrue((mfi_norm <= 1).all())\n","\n","# Run tests\n","suite = unittest.TestLoader().loadTestsFromTestCase(TestMFIFeature)\n","runner = unittest.TextTestRunner(verbosity=2)\n","result = runner.run(suite)\n","print(f\"\\nTests run: {result.testsRun}, Failures: {len(result.failures)}, Errors: {len(result.errors)}\")"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1765070481374,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"ToKcL88ZCRrn","outputId":"dd1a419b-0f0d-45e4-fc90-06fcbe950976"},"outputs":[{"output_type":"stream","name":"stderr","text":["test_gap_formula (__main__.TestTimeGapFeature.test_gap_formula)\n","Verify gap formula: ln(1 + max(Δt_min - 1, 0)). ... ok\n","test_gap_positive_for_breaks (__main__.TestTimeGapFeature.test_gap_positive_for_breaks)\n","Verify gap > 0 for time breaks. ... ok\n","test_gap_zero_for_consecutive_bars (__main__.TestTimeGapFeature.test_gap_zero_for_consecutive_bars)\n","Verify gap = 0 for consecutive 1-minute bars. ... ok\n","\n","----------------------------------------------------------------------\n","Ran 3 tests in 0.044s\n","\n","OK\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tests run: 3, Failures: 0, Errors: 0\n"]}],"source":["class TestTimeGapFeature(unittest.TestCase):\n","    \"\"\"Test temporal gap feature computation.\"\"\"\n","\n","    def test_gap_zero_for_consecutive_bars(self):\n","        \"\"\"Verify gap = 0 for consecutive 1-minute bars.\"\"\"\n","        df = generate_synthetic_ohlcv(\n","            n_bars=100,\n","            include_gaps=False,\n","            seed=444\n","        )\n","\n","        fe = FeatureEngineer()\n","        features = fe.compute_all_features(df)\n","\n","        # All gaps should be 0 (after first bar)\n","        gaps = features['time_gap'].dropna()\n","        self.assertTrue((gaps.iloc[1:] == 0).all())\n","\n","    def test_gap_positive_for_breaks(self):\n","        \"\"\"Verify gap > 0 for time breaks.\"\"\"\n","        # Create data with explicit gap\n","        df = pd.DataFrame({\n","            'timestamp': [\n","                pd.Timestamp('2023-01-03 09:00:00'),\n","                pd.Timestamp('2023-01-03 09:01:00'),\n","                pd.Timestamp('2023-01-03 09:05:00'),  # 4-minute gap\n","                pd.Timestamp('2023-01-03 09:06:00'),\n","            ],\n","            'open': [100, 100, 100, 100],\n","            'high': [101, 101, 101, 101],\n","            'low': [99, 99, 99, 99],\n","            'close': [100, 100, 100, 100],\n","            'volume': [1000, 1000, 1000, 1000]\n","        })\n","\n","        fe = FeatureEngineer()\n","        features = fe.compute_all_features(df)\n","\n","        # Gap at index 2 should be ln(1 + (4 - 1)) = ln(4)\n","        expected_gap = np.log(4)\n","        actual_gap = features.loc[2, 'time_gap']\n","\n","        self.assertAlmostEqual(actual_gap, expected_gap, places=5)\n","\n","    def test_gap_formula(self):\n","        \"\"\"Verify gap formula: ln(1 + max(Δt_min - 1, 0)).\"\"\"\n","        # Per grok-scientific.md: gap = ln(1 + ((t_i - t_{i-1}) / 60 - 1))\n","        df = pd.DataFrame({\n","            'timestamp': [\n","                pd.Timestamp('2023-01-03 09:00:00'),\n","                pd.Timestamp('2023-01-03 09:01:00'),   # Δt = 1 min -> gap = 0\n","                pd.Timestamp('2023-01-03 09:03:00'),   # Δt = 2 min -> gap = ln(2)\n","                pd.Timestamp('2023-01-03 09:13:00'),   # Δt = 10 min -> gap = ln(10)\n","            ],\n","            'open': [100, 100, 100, 100],\n","            'high': [101, 101, 101, 101],\n","            'low': [99, 99, 99, 99],\n","            'close': [100, 100, 100, 100],\n","            'volume': [1000, 1000, 1000, 1000]\n","        })\n","\n","        fe = FeatureEngineer()\n","        features = fe.compute_all_features(df)\n","\n","        # Check each gap\n","        self.assertAlmostEqual(features.loc[1, 'time_gap'], 0.0, places=5)\n","        self.assertAlmostEqual(features.loc[2, 'time_gap'], np.log(2), places=5)\n","        self.assertAlmostEqual(features.loc[3, 'time_gap'], np.log(10), places=5)\n","\n","# Run tests\n","suite = unittest.TestLoader().loadTestsFromTestCase(TestTimeGapFeature)\n","runner = unittest.TextTestRunner(verbosity=2)\n","result = runner.run(suite)\n","print(f\"\\nTests run: {result.testsRun}, Failures: {len(result.failures)}, Errors: {len(result.errors)}\")"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1765070481410,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"4hQqlOCwCRro","outputId":"c79ea87c-bbcc-463e-a561-0127f509b83e"},"outputs":[{"output_type":"stream","name":"stderr","text":["test_target_formula (__main__.TestTargetComputation.test_target_formula)\n","Verify target_h = ln(close_{t+h} / close_t). ... ok\n","test_target_horizons (__main__.TestTargetComputation.test_target_horizons)\n","Verify targets computed for all 6 horizons. ... ok\n","test_target_nan_at_end (__main__.TestTargetComputation.test_target_nan_at_end)\n","Verify targets are NaN at end of dataset. ... ok\n","\n","----------------------------------------------------------------------\n","Ran 3 tests in 0.013s\n","\n","OK\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tests run: 3, Failures: 0, Errors: 0\n"]}],"source":["class TestTargetComputation(unittest.TestCase):\n","    \"\"\"Test forward return target computation.\"\"\"\n","\n","    @classmethod\n","    def setUpClass(cls):\n","        cls.df = generate_synthetic_ohlcv(n_bars=1000, seed=555)\n","        cls.fe = FeatureEngineer()\n","\n","    def test_target_horizons(self):\n","        \"\"\"Verify targets computed for all 6 horizons.\"\"\"\n","        targets = self.fe.compute_targets(self.df)\n","\n","        expected_cols = [\n","            'timestamp', 'target_5m', 'target_15m', 'target_30m',\n","            'target_60m', 'target_120m', 'target_240m'\n","        ]\n","\n","        for col in expected_cols:\n","            self.assertIn(col, targets.columns)\n","\n","    def test_target_formula(self):\n","        \"\"\"Verify target_h = ln(close_{t+h} / close_t).\"\"\"\n","        targets = self.fe.compute_targets(self.df)\n","\n","        # Check 5m target\n","        expected_5m = np.log(self.df['close'].shift(-5) / self.df['close'])\n","        actual_5m = targets['target_5m']\n","\n","        # Compare valid values (not NaN at end)\n","        valid_mask = ~expected_5m.isna()\n","        np.testing.assert_array_almost_equal(\n","            actual_5m[valid_mask].values,\n","            expected_5m[valid_mask].values,\n","            decimal=10\n","        )\n","\n","    def test_target_nan_at_end(self):\n","        \"\"\"Verify targets are NaN at end of dataset.\"\"\"\n","        targets = self.fe.compute_targets(self.df)\n","\n","        # Last 240 rows should have NaN for 240m target\n","        self.assertTrue(targets['target_240m'].iloc[-240:].isna().all())\n","\n","        # Last 5 rows should have NaN for 5m target\n","        self.assertTrue(targets['target_5m'].iloc[-5:].isna().all())\n","\n","# Run tests\n","suite = unittest.TestLoader().loadTestsFromTestCase(TestTargetComputation)\n","runner = unittest.TextTestRunner(verbosity=2)\n","result = runner.run(suite)\n","print(f\"\\nTests run: {result.testsRun}, Failures: {len(result.failures)}, Errors: {len(result.errors)}\")"]},{"cell_type":"markdown","metadata":{"id":"jimUAoPKCRro"},"source":["## 4. Integration Tests"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1765070481453,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"DGbZgrVZCRro","outputId":"6705e6d2-12ee-4b73-ef98-2868125323f0"},"outputs":[{"output_type":"stream","name":"stderr","text":["test_all_features_present (__main__.TestFullPipeline.test_all_features_present)\n","Verify all 24 features are computed. ... ok\n","test_feature_group_indices (__main__.TestFullPipeline.test_feature_group_indices)\n","Verify feature indices match column positions. ... ok\n","test_nan_rate_after_warmup (__main__.TestFullPipeline.test_nan_rate_after_warmup)\n","Verify NaN rate is acceptable after warmup. ... ok\n","test_no_inf_values (__main__.TestFullPipeline.test_no_inf_values)\n","Verify no infinite values in features. ... ok\n","test_output_shape (__main__.TestFullPipeline.test_output_shape)\n","Verify output dimensions match input. ... ok\n","test_timestamp_alignment (__main__.TestFullPipeline.test_timestamp_alignment)\n","Verify features and targets have aligned timestamps. ... ok\n","\n","----------------------------------------------------------------------\n","Ran 6 tests in 0.140s\n","\n","OK\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tests run: 6, Failures: 0, Errors: 0\n"]}],"source":["class TestFullPipeline(unittest.TestCase):\n","    \"\"\"Integration tests for complete feature engineering pipeline.\"\"\"\n","\n","    @classmethod\n","    def setUpClass(cls):\n","        \"\"\"Generate larger test dataset.\"\"\"\n","        cls.df = generate_synthetic_ohlcv(n_bars=10000, seed=666)\n","        cls.fe = FeatureEngineer()\n","        cls.features = cls.fe.compute_all_features(cls.df)\n","        cls.targets = cls.fe.compute_targets(cls.df)\n","\n","    def test_output_shape(self):\n","        \"\"\"Verify output dimensions match input.\"\"\"\n","        self.assertEqual(len(self.features), len(self.df))\n","        self.assertEqual(len(self.targets), len(self.df))\n","\n","    def test_all_features_present(self):\n","        \"\"\"Verify all 24 features are computed.\"\"\"\n","        for col in FEATURE_COLUMNS:\n","            self.assertIn(\n","                col, self.features.columns,\n","                f\"Missing feature: {col}\"\n","            )\n","\n","    def test_nan_rate_after_warmup(self):\n","        \"\"\"Verify NaN rate is acceptable after warmup.\"\"\"\n","        # Skip warmup period\n","        warmup = self.fe.warmup_period\n","        features_valid = self.features.iloc[warmup:]\n","\n","        nan_rate = features_valid[FEATURE_COLUMNS].isna().mean().mean()\n","\n","        # NaN rate should be < 1% after warmup\n","        self.assertLess(\n","            nan_rate, 0.01,\n","            f\"NaN rate {100*nan_rate:.2f}% exceeds 1% threshold\"\n","        )\n","\n","    def test_no_inf_values(self):\n","        \"\"\"Verify no infinite values in features.\"\"\"\n","        has_inf = np.isinf(self.features[FEATURE_COLUMNS]).any().any()\n","        self.assertFalse(has_inf, \"Features contain infinite values\")\n","\n","    def test_feature_group_indices(self):\n","        \"\"\"Verify feature indices match column positions.\"\"\"\n","        indices = self.fe.get_feature_indices()\n","\n","        for group_name, group_indices in indices.items():\n","            group_features = FEATURE_GROUPS[group_name]\n","\n","            for i, feat in zip(group_indices, group_features):\n","                self.assertEqual(\n","                    FEATURE_COLUMNS[i], feat,\n","                    f\"Index mismatch for {feat} in group {group_name}\"\n","                )\n","\n","    def test_timestamp_alignment(self):\n","        \"\"\"Verify features and targets have aligned timestamps.\"\"\"\n","        pd.testing.assert_series_equal(\n","            self.features['timestamp'],\n","            self.targets['timestamp'],\n","            check_names=False\n","        )\n","\n","# Run tests\n","suite = unittest.TestLoader().loadTestsFromTestCase(TestFullPipeline)\n","runner = unittest.TextTestRunner(verbosity=2)\n","result = runner.run(suite)\n","print(f\"\\nTests run: {result.testsRun}, Failures: {len(result.failures)}, Errors: {len(result.errors)}\")"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":99,"status":"ok","timestamp":1765070481570,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"6_DEFD15CRrp","outputId":"efb1ff69-60de-470d-cc48-b2279c277e39"},"outputs":[{"output_type":"stream","name":"stderr","text":["test_roundtrip (__main__.TestParquetSaveLoad.test_roundtrip)\n","Verify features survive save/load roundtrip. ... ok\n","\n","----------------------------------------------------------------------\n","Ran 1 test in 0.160s\n","\n","OK\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tests run: 1, Failures: 0, Errors: 0\n"]}],"source":["class TestParquetSaveLoad(unittest.TestCase):\n","    \"\"\"Test saving and loading features to/from Parquet.\"\"\"\n","\n","    def test_roundtrip(self):\n","        \"\"\"Verify features survive save/load roundtrip.\"\"\"\n","        import tempfile\n","        import os\n","\n","        # Generate features\n","        df = generate_synthetic_ohlcv(n_bars=1000, seed=777)\n","        fe = FeatureEngineer()\n","        features = fe.compute_all_features(df)\n","\n","        # Save to temp file\n","        with tempfile.TemporaryDirectory() as tmpdir:\n","            path = os.path.join(tmpdir, 'test_features.parquet')\n","            features.to_parquet(path, engine='pyarrow')\n","\n","            # Load back\n","            loaded = pd.read_parquet(path)\n","\n","        # Verify equality\n","        pd.testing.assert_frame_equal(\n","            features.reset_index(drop=True),\n","            loaded.reset_index(drop=True),\n","            check_exact=False,\n","            rtol=1e-10\n","        )\n","\n","# Run tests\n","suite = unittest.TestLoader().loadTestsFromTestCase(TestParquetSaveLoad)\n","runner = unittest.TextTestRunner(verbosity=2)\n","result = runner.run(suite)\n","print(f\"\\nTests run: {result.testsRun}, Failures: {len(result.failures)}, Errors: {len(result.errors)}\")"]},{"cell_type":"markdown","metadata":{"id":"jzZ_lBCnCRrq"},"source":["## 5. Data Acquisition Tests (Mocked)\n","\n","These tests verify the acquisition module logic without making actual API calls."]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1765070481630,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"egifeqExCRrq","outputId":"34456716-229d-4eb8-8ffd-d5d1cab0298a"},"outputs":[{"output_type":"stream","name":"stderr","text":["test_dataset_cme (__main__.TestDatabentoConfig.test_dataset_cme)\n","Verify dataset is CME Globex. ... ok\n","test_date_range (__main__.TestDatabentoConfig.test_date_range)\n","Verify date range matches problem statement. ... ok\n","test_schema_1min (__main__.TestDatabentoConfig.test_schema_1min)\n","Verify schema is 1-minute OHLCV. ... ok\n","test_symbol_volume_based (__main__.TestDatabentoConfig.test_symbol_volume_based)\n","Verify symbol uses volume-based rollover per problem statement. ... ok\n","\n","----------------------------------------------------------------------\n","Ran 4 tests in 0.002s\n","\n","OK\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tests run: 4, Failures: 0, Errors: 0\n"]}],"source":["from src.data.acquisition import DatabentoConfig, NQDataAcquisition\n","\n","class TestDatabentoConfig(unittest.TestCase):\n","    \"\"\"Test Databento configuration constants.\"\"\"\n","\n","    def test_symbol_volume_based(self):\n","        \"\"\"Verify symbol uses volume-based rollover per problem statement.\"\"\"\n","        self.assertEqual(DatabentoConfig.SYMBOL, \"NQ.v.0\")\n","        self.assertIn('.v.', DatabentoConfig.SYMBOL)  # Volume-based indicator\n","\n","    def test_schema_1min(self):\n","        \"\"\"Verify schema is 1-minute OHLCV.\"\"\"\n","        self.assertEqual(DatabentoConfig.SCHEMA, \"ohlcv-1m\")\n","\n","    def test_date_range(self):\n","        \"\"\"Verify date range matches problem statement.\"\"\"\n","        self.assertEqual(DatabentoConfig.START_DATE, \"2010-06-06\")\n","        self.assertEqual(DatabentoConfig.END_DATE, \"2025-12-03\")\n","\n","    def test_dataset_cme(self):\n","        \"\"\"Verify dataset is CME Globex.\"\"\"\n","        self.assertEqual(DatabentoConfig.DATASET, \"GLBX.MDP3\")\n","\n","# Run tests\n","suite = unittest.TestLoader().loadTestsFromTestCase(TestDatabentoConfig)\n","runner = unittest.TextTestRunner(verbosity=2)\n","result = runner.run(suite)\n","print(f\"\\nTests run: {result.testsRun}, Failures: {len(result.failures)}, Errors: {len(result.errors)}\")"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1765070481663,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"ES6lIbLqCRrr","outputId":"2860de96-dcfa-43a4-8d4d-bddd4a2c95ed"},"outputs":[{"output_type":"stream","name":"stderr","text":["test_price_sanity_check (__main__.TestOHLCVValidation.test_price_sanity_check)\n","Verify price sanity check catches scaling bugs. ... ok\n","test_valid_ohlcv_passes (__main__.TestOHLCVValidation.test_valid_ohlcv_passes)\n","Verify valid OHLCV data passes validation. ... ok\n","\n","----------------------------------------------------------------------\n","Ran 2 tests in 0.004s\n","\n","OK\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tests run: 2, Failures: 0, Errors: 0\n"]}],"source":["class TestOHLCVValidation(unittest.TestCase):\n","    \"\"\"Test OHLCV validation logic.\"\"\"\n","\n","    def test_valid_ohlcv_passes(self):\n","        \"\"\"Verify valid OHLCV data passes validation.\"\"\"\n","        df = generate_synthetic_ohlcv(n_bars=100, seed=888)\n","\n","        # Should not raise\n","        try:\n","            # Simulate validation checks\n","            invalid_hl = (df['high'] < df['low']).sum()\n","            invalid_oh = (df['open'] > df['high']).sum()\n","            invalid_ol = (df['open'] < df['low']).sum()\n","            invalid_ch = (df['close'] > df['high']).sum()\n","            invalid_cl = (df['close'] < df['low']).sum()\n","\n","            total_invalid = invalid_hl + invalid_oh + invalid_ol + invalid_ch + invalid_cl\n","            self.assertEqual(total_invalid, 0)\n","        except Exception as e:\n","            self.fail(f\"Validation raised exception: {e}\")\n","\n","    def test_price_sanity_check(self):\n","        \"\"\"Verify price sanity check catches scaling bugs.\"\"\"\n","        df = generate_synthetic_ohlcv(n_bars=100, start_price=15000, seed=999)\n","\n","        # Median should be in thousands (NQ typical range)\n","        median_price = df['close'].median()\n","        self.assertGreater(median_price, 100)\n","\n","        # Simulate scaled-down bug\n","        df_bug = df.copy()\n","        df_bug['close'] = df_bug['close'] * 1e-9  # Bug: double-scaling\n","        median_bug = df_bug['close'].median()\n","\n","        # This would fail sanity check\n","        self.assertLess(median_bug, 100)\n","\n","# Run tests\n","suite = unittest.TestLoader().loadTestsFromTestCase(TestOHLCVValidation)\n","runner = unittest.TextTestRunner(verbosity=2)\n","result = runner.run(suite)\n","print(f\"\\nTests run: {result.testsRun}, Failures: {len(result.failures)}, Errors: {len(result.errors)}\")"]},{"cell_type":"markdown","metadata":{"id":"aUS-5Z_TCRrr"},"source":["## 6. Run All Tests Summary"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":594,"status":"ok","timestamp":1765070482267,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"k5isTIf9CRrr","outputId":"743b0081-e8e9-4b63-da00-03977b1fdceb"},"outputs":[{"output_type":"stream","name":"stderr","text":["test_custom_initialization (__main__.TestFeatureEngineerInit.test_custom_initialization)\n","Verify custom parameters are applied. ... ok\n","test_default_initialization (__main__.TestFeatureEngineerInit.test_default_initialization)\n","Verify default parameters are set correctly. ... ok\n","test_warmup_period_calculation (__main__.TestFeatureEngineerInit.test_warmup_period_calculation)\n","Verify warmup period is correctly computed. ... ok\n","test_feature_count (__main__.TestFeatureColumns.test_feature_count)\n","Verify exactly 24 features per grok-scientific.md Section 3.1. ... ok\n","test_feature_group_sizes (__main__.TestFeatureColumns.test_feature_group_sizes)\n","Verify feature group sizes per grok-scientific.md. ... ok\n","test_feature_groups_coverage (__main__.TestFeatureColumns.test_feature_groups_coverage)\n","Verify all features belong to exactly one group. ... ok\n","test_flow_group_features (__main__.TestFeatureColumns.test_flow_group_features)\n","Verify flow group contains MFI and time_gap. ... ok\n","test_price_group_features (__main__.TestFeatureColumns.test_price_group_features)\n","Verify price group contains expected features. ... ok\n"]},{"output_type":"stream","name":"stdout","text":["======================================================================\n","RUNNING ALL DEV PHASE 1 TESTS\n","======================================================================\n"]},{"output_type":"stream","name":"stderr","text":["test_close_location_bounds (__main__.TestPriceDynamicsFeatures.test_close_location_bounds)\n","Verify close_location is in [0, 1]. ... ok\n","test_hl_range_positive (__main__.TestPriceDynamicsFeatures.test_hl_range_positive)\n","Verify hl_range is always non-negative. ... ok\n","test_log_return_calculation (__main__.TestPriceDynamicsFeatures.test_log_return_calculation)\n","Verify log_return = ln(close_t / close_{t-1}). ... ok\n","test_log_return_stationarity (__main__.TestPriceDynamicsFeatures.test_log_return_stationarity)\n","Verify log returns have near-zero mean (stationarity). ... ok\n","test_open_return_calculation (__main__.TestPriceDynamicsFeatures.test_open_return_calculation)\n","Verify open_return = ln(close / open). ... ok\n","test_dollar_volume_calculation (__main__.TestVolumeFeatures.test_dollar_volume_calculation)\n","Verify dollar_volume = log1p(close * volume). ... ok\n","test_log_volume_delta_calculation (__main__.TestVolumeFeatures.test_log_volume_delta_calculation)\n","Verify log_volume_delta is difference of log volumes. ... ok\n","test_log_volume_handles_zero (__main__.TestVolumeFeatures.test_log_volume_handles_zero)\n","Verify log_volume uses log1p to handle zero volume. ... ok\n","test_dmi_components_bounds (__main__.TestMomentumFeatures.test_dmi_components_bounds)\n","Verify +DI, -DI, ADX are in [0, 1] after normalization. ... ok\n","test_roc_calculation (__main__.TestMomentumFeatures.test_roc_calculation)\n","Verify roc_norm = (close_t / close_{t-10}) - 1. ... ok\n","test_rsi_norm_bounds (__main__.TestMomentumFeatures.test_rsi_norm_bounds)\n","Verify rsi_norm is in [-1, 1] after warmup. ... ok\n","test_rsi_norm_transformation (__main__.TestMomentumFeatures.test_rsi_norm_transformation)\n","Verify rsi_norm = (RSI - 50) / 50. ... ok\n","test_atr_norm_positive (__main__.TestVolatilityFeatures.test_atr_norm_positive)\n","Verify ATR is always positive. ... ok\n","test_bb_bandwidth_positive (__main__.TestVolatilityFeatures.test_bb_bandwidth_positive)\n","Verify Bollinger bandwidth is positive. ... ok\n","test_bb_pct_b_bounds (__main__.TestVolatilityFeatures.test_bb_pct_b_bounds)\n","Verify Bollinger %B is roughly in [0, 1] for normal prices. ... ok\n","test_realized_vol_annualization (__main__.TestVolatilityFeatures.test_realized_vol_annualization)\n","Verify realized vol is annualized (reasonable magnitude). ... ok\n","test_realized_vol_positive (__main__.TestVolatilityFeatures.test_realized_vol_positive)\n","Verify realized volatility is non-negative. ... ok\n","test_vwap_deviation_bounded (__main__.TestVWAPFeature.test_vwap_deviation_bounded)\n","Verify VWAP deviation is reasonably bounded. ... ok\n","test_vwap_session_reset (__main__.TestVWAPFeature.test_vwap_session_reset)\n","Verify VWAP resets at RTH open (09:30 ET). ... ok\n","test_mfi_norm_bounds (__main__.TestMFIFeature.test_mfi_norm_bounds)\n","Verify mfi_norm is in [-1, 1]. ... ok\n","test_mfi_uses_typical_price_direction (__main__.TestMFIFeature.test_mfi_uses_typical_price_direction)\n","Verify MFI uses typical price direction, not close price direction. ... ok\n","test_gap_formula (__main__.TestTimeGapFeature.test_gap_formula)\n","Verify gap formula: ln(1 + max(Δt_min - 1, 0)). ... ok\n","test_gap_positive_for_breaks (__main__.TestTimeGapFeature.test_gap_positive_for_breaks)\n","Verify gap > 0 for time breaks. ... ok\n","test_gap_zero_for_consecutive_bars (__main__.TestTimeGapFeature.test_gap_zero_for_consecutive_bars)\n","Verify gap = 0 for consecutive 1-minute bars. ... ok\n","test_target_formula (__main__.TestTargetComputation.test_target_formula)\n","Verify target_h = ln(close_{t+h} / close_t). ... ok\n","test_target_horizons (__main__.TestTargetComputation.test_target_horizons)\n","Verify targets computed for all 6 horizons. ... ok\n","test_target_nan_at_end (__main__.TestTargetComputation.test_target_nan_at_end)\n","Verify targets are NaN at end of dataset. ... ok\n","test_all_features_present (__main__.TestFullPipeline.test_all_features_present)\n","Verify all 24 features are computed. ... ok\n","test_feature_group_indices (__main__.TestFullPipeline.test_feature_group_indices)\n","Verify feature indices match column positions. ... ok\n","test_nan_rate_after_warmup (__main__.TestFullPipeline.test_nan_rate_after_warmup)\n","Verify NaN rate is acceptable after warmup. ... ok\n","test_no_inf_values (__main__.TestFullPipeline.test_no_inf_values)\n","Verify no infinite values in features. ... ok\n","test_output_shape (__main__.TestFullPipeline.test_output_shape)\n","Verify output dimensions match input. ... ok\n","test_timestamp_alignment (__main__.TestFullPipeline.test_timestamp_alignment)\n","Verify features and targets have aligned timestamps. ... ok\n","test_roundtrip (__main__.TestParquetSaveLoad.test_roundtrip)\n","Verify features survive save/load roundtrip. ... ok\n","test_dataset_cme (__main__.TestDatabentoConfig.test_dataset_cme)\n","Verify dataset is CME Globex. ... ok\n","test_date_range (__main__.TestDatabentoConfig.test_date_range)\n","Verify date range matches problem statement. ... ok\n","test_schema_1min (__main__.TestDatabentoConfig.test_schema_1min)\n","Verify schema is 1-minute OHLCV. ... ok\n","test_symbol_volume_based (__main__.TestDatabentoConfig.test_symbol_volume_based)\n","Verify symbol uses volume-based rollover per problem statement. ... ok\n","test_price_sanity_check (__main__.TestOHLCVValidation.test_price_sanity_check)\n","Verify price sanity check catches scaling bugs. ... ok\n","test_valid_ohlcv_passes (__main__.TestOHLCVValidation.test_valid_ohlcv_passes)\n","Verify valid OHLCV data passes validation. ... ok\n","\n","----------------------------------------------------------------------\n","Ran 48 tests in 0.505s\n","\n","OK\n"]},{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","TEST SUMMARY\n","======================================================================\n","Tests run: 48\n","Failures: 0\n","Errors: 0\n","Success: True\n"]}],"source":["# Collect all test classes\n","test_classes = [\n","    TestFeatureEngineerInit,\n","    TestFeatureColumns,\n","    TestPriceDynamicsFeatures,\n","    TestVolumeFeatures,\n","    TestMomentumFeatures,\n","    TestVolatilityFeatures,\n","    TestVWAPFeature,\n","    TestMFIFeature,\n","    TestTimeGapFeature,\n","    TestTargetComputation,\n","    TestFullPipeline,\n","    TestParquetSaveLoad,\n","    TestDatabentoConfig,\n","    TestOHLCVValidation,\n","]\n","\n","# Create suite\n","loader = unittest.TestLoader()\n","suite = unittest.TestSuite()\n","\n","for test_class in test_classes:\n","    suite.addTests(loader.loadTestsFromTestCase(test_class))\n","\n","# Run all tests\n","print(\"=\"*70)\n","print(\"RUNNING ALL DEV PHASE 1 TESTS\")\n","print(\"=\"*70)\n","\n","runner = unittest.TextTestRunner(verbosity=2)\n","result = runner.run(suite)\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"TEST SUMMARY\")\n","print(\"=\"*70)\n","print(f\"Tests run: {result.testsRun}\")\n","print(f\"Failures: {len(result.failures)}\")\n","print(f\"Errors: {len(result.errors)}\")\n","print(f\"Success: {result.wasSuccessful()}\")\n","\n","if result.failures:\n","    print(\"\\nFailed tests:\")\n","    for test, traceback in result.failures:\n","        print(f\"  - {test}\")\n","\n","if result.errors:\n","    print(\"\\nErrors:\")\n","    for test, traceback in result.errors:\n","        print(f\"  - {test}\")"]},{"cell_type":"markdown","metadata":{"id":"C3LcvIoUCRrs"},"source":["## 7. Validation Criteria Check\n","\n","Per claude-engineering.md Section 4.1.4 Phase 1 Validation Criteria."]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1154,"status":"ok","timestamp":1765070483435,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"qQBSeFBECRrs","outputId":"d200e281-a567-4f2b-fdd0-8194f356bec0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Phase 1 Validation Criteria Check\n","==================================================\n","\n","1. Data completeness: 100,000 rows\n","   Target: >5M rows (will be met with real data)\n","   Status: ✓ (using synthetic data)\n","\n","2. OHLC validity: 0.0000% invalid bars\n","   Target: <0.1% invalid bars\n","   Status: ✓\n","\n","3. Feature NaN rate (after warmup): 0.0000%\n","   Target: <1% after warmup\n","   Status: ✓\n","\n","4. Feature count: 24\n","   Target: 24 features per grok-scientific.md\n","   Status: ✓\n","\n","5. Feature groups: 6\n","   Target: 6 groups for TSA\n","   Status: ✓\n","\n","6. Parquet size estimate: 1316.1 MB for 5M rows\n","   Target: <500MB per file\n","   Status: ✗\n","\n","==================================================\n","All Phase 1 validation criteria checked!\n"]}],"source":["def check_validation_criteria():\n","    \"\"\"Check Phase 1 validation criteria per claude-engineering.md.\"\"\"\n","\n","    print(\"Phase 1 Validation Criteria Check\")\n","    print(\"=\"*50)\n","\n","    # Generate larger dataset for realistic checks\n","    df = generate_synthetic_ohlcv(n_bars=100000, seed=12345)\n","    fe = FeatureEngineer()\n","\n","    print(f\"\\n1. Data completeness: {len(df):,} rows\")\n","    print(f\"   Target: >5M rows (will be met with real data)\")\n","    print(f\"   Status: {'✓' if len(df) > 0 else '✗'} (using synthetic data)\")\n","\n","    # Compute features\n","    features = fe.compute_all_features(df)\n","\n","    # OHLC validity\n","    invalid_hl = (df['high'] < df['low']).sum()\n","    invalid_rate = invalid_hl / len(df)\n","    print(f\"\\n2. OHLC validity: {100*invalid_rate:.4f}% invalid bars\")\n","    print(f\"   Target: <0.1% invalid bars\")\n","    print(f\"   Status: {'✓' if invalid_rate < 0.001 else '✗'}\")\n","\n","    # Feature NaN rate after warmup\n","    warmup = fe.warmup_period\n","    features_valid = features.iloc[warmup:]\n","    nan_rate = features_valid[FEATURE_COLUMNS].isna().mean().mean()\n","    print(f\"\\n3. Feature NaN rate (after warmup): {100*nan_rate:.4f}%\")\n","    print(f\"   Target: <1% after warmup\")\n","    print(f\"   Status: {'✓' if nan_rate < 0.01 else '✗'}\")\n","\n","    # Feature count\n","    print(f\"\\n4. Feature count: {len(FEATURE_COLUMNS)}\")\n","    print(f\"   Target: 24 features per grok-scientific.md\")\n","    print(f\"   Status: {'✓' if len(FEATURE_COLUMNS) == 24 else '✗'}\")\n","\n","    # Feature groups\n","    print(f\"\\n5. Feature groups: {len(FEATURE_GROUPS)}\")\n","    print(f\"   Target: 6 groups for TSA\")\n","    print(f\"   Status: {'✓' if len(FEATURE_GROUPS) == 6 else '✗'}\")\n","\n","    # Parquet estimate\n","    import tempfile\n","    import os\n","\n","    with tempfile.TemporaryDirectory() as tmpdir:\n","        path = os.path.join(tmpdir, 'test.parquet')\n","        features.to_parquet(path, compression='snappy')\n","        size_mb = os.path.getsize(path) / (1024 * 1024)\n","\n","    # Scale estimate for full dataset (~5M rows)\n","    estimated_full_size = size_mb * (5_000_000 / len(features))\n","    print(f\"\\n6. Parquet size estimate: {estimated_full_size:.1f} MB for 5M rows\")\n","    print(f\"   Target: <500MB per file\")\n","    print(f\"   Status: {'✓' if estimated_full_size < 500 else '✗'}\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"All Phase 1 validation criteria checked!\")\n","\n","check_validation_criteria()"]},{"cell_type":"markdown","metadata":{"id":"6t63CVLtCRrt"},"source":["## 8. Feature Statistics Visualization"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":447,"status":"ok","timestamp":1765070483921,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"Xos8lA8BCRrt","outputId":"88618c51-54cd-4b2e-8a80-86f3d4d6b46d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Feature Statistics (after warmup period)\n","================================================================================\n","         Feature    Mean    Std     Min     Max NaN%\n","      log_return -0.0000 0.0002 -0.0008  0.0008 0.00\n","        hl_range  0.0003 0.0002  0.0000  0.0018 0.00\n","  close_location  0.4972 0.1723  0.2000  0.7999 0.00\n","     open_return -0.0000 0.0001 -0.0005  0.0006 0.00\n","      log_volume  6.3327 1.2709  0.0000  9.2581 0.00\n","log_volume_delta -0.0002 1.8001 -7.3740  8.1062 0.00\n","   dollar_volume 15.9377 1.3533  0.0000 18.8668 0.00\n","  vwap_deviation -0.0005 0.0031 -0.0099  0.0081 0.00\n","  macd_histogram -0.0000 0.0001 -0.0003  0.0002 0.00\n","      sma_20_dev -0.0000 0.0005 -0.0017  0.0015 0.00\n","      sma_50_dev -0.0000 0.0008 -0.0025  0.0025 0.00\n","     sma_200_dev -0.0000 0.0016 -0.0056  0.0050 0.00\n","        rsi_norm -0.0012 0.2303 -0.6810  0.7196 0.00\n","             cci  0.0005 1.0731 -3.1748  3.5178 0.00\n","         plus_di  0.2591 0.0994  0.0310  0.6637 0.00\n","        minus_di  0.2588 0.0960  0.0282  0.6102 0.00\n","             adx  0.2827 0.1070  0.0761  0.7454 0.00\n","        roc_norm -0.0000 0.0006 -0.0023  0.0024 0.00\n","        atr_norm  0.0004 0.0001  0.0002  0.0007 0.00\n","        bb_pct_b  0.4999 0.3214 -0.3548  1.3677 0.00\n","    bb_bandwidth  0.0013 0.0005  0.0004  0.0038 0.00\n","    realized_vol  0.0623 0.0100  0.0331  0.1001 0.00\n","        mfi_norm -0.0076 0.3511 -0.9784  0.9924 0.00\n","        time_gap  0.0038 0.1363  0.0000  7.9862 0.00\n"]}],"source":["def display_feature_statistics():\n","    \"\"\"Display summary statistics for all features.\"\"\"\n","\n","    df = generate_synthetic_ohlcv(n_bars=10000, seed=42)\n","    fe = FeatureEngineer()\n","    features = fe.compute_all_features(df)\n","\n","    # Skip warmup\n","    features_valid = features.iloc[fe.warmup_period:]\n","\n","    print(\"Feature Statistics (after warmup period)\")\n","    print(\"=\"*80)\n","\n","    stats_data = []\n","    for col in FEATURE_COLUMNS:\n","        values = features_valid[col].dropna()\n","        stats_data.append({\n","            'Feature': col,\n","            'Mean': f\"{values.mean():.4f}\",\n","            'Std': f\"{values.std():.4f}\",\n","            'Min': f\"{values.min():.4f}\",\n","            'Max': f\"{values.max():.4f}\",\n","            'NaN%': f\"{100*values.isna().mean():.2f}\"\n","        })\n","\n","    stats_df = pd.DataFrame(stats_data)\n","    print(stats_df.to_string(index=False))\n","\n","    return stats_df\n","\n","stats = display_feature_statistics()"]},{"cell_type":"markdown","metadata":{"id":"WQvZIRjtCRrt"},"source":["## 9. End-to-End Demo\n","\n","Demonstrates the complete Phase 1 workflow (with synthetic data)."]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":447,"status":"ok","timestamp":1765070484383,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"rm1QwGMBCRrt","outputId":"6a1bf4ea-e6f3-4184-ae01-b5e2836e6cfe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dev Phase 1 End-to-End Demo\n","============================================================\n","\n","[Step 1] Generating synthetic OHLCV data...\n","  Generated 50,000 bars\n","  Date range: 2023-01-03 18:00:00 to 2023-02-23 06:12:00\n","\n","[Step 2] Computing features...\n","  Computed 24 features\n","  Feature groups: ['price', 'volume', 'trend', 'momentum', 'volatility', 'flow']\n","\n","[Step 3] Computing targets...\n","  Computed targets for horizons: ['target_5m', 'target_15m', 'target_30m', 'target_60m', 'target_120m', 'target_240m']\n","\n","[Step 4] Saving to parquet...\n","  Features: 13.04 MB\n","  Targets: 3.29 MB\n","\n","[Step 5] Verifying roundtrip...\n","  Features shape match: True\n","  Targets shape match: True\n","\n","============================================================\n","Phase 1 Demo Complete!\n","\n","Next steps:\n","  1. Run acquisition with real Databento API\n","  2. Process full 15-year dataset\n","  3. Save to Google Drive for Phase 2\n"]}],"source":["def run_phase1_demo():\n","    \"\"\"\n","    Demonstrate complete Phase 1 workflow.\n","\n","    This uses synthetic data to show the pipeline without\n","    requiring Databento API access.\n","    \"\"\"\n","    import tempfile\n","    import os\n","\n","    print(\"Dev Phase 1 End-to-End Demo\")\n","    print(\"=\"*60)\n","\n","    # Step 1: Generate synthetic OHLCV data (simulates acquisition)\n","    print(\"\\n[Step 1] Generating synthetic OHLCV data...\")\n","    raw_df = generate_synthetic_ohlcv(\n","        n_bars=50000,\n","        start_price=15000,\n","        volatility=0.0002,\n","        start_date=\"2023-01-03 18:00:00\",\n","        include_gaps=True,\n","        seed=42\n","    )\n","    print(f\"  Generated {len(raw_df):,} bars\")\n","    print(f\"  Date range: {raw_df['timestamp'].min()} to {raw_df['timestamp'].max()}\")\n","\n","    # Step 2: Compute features\n","    print(\"\\n[Step 2] Computing features...\")\n","    fe = FeatureEngineer()\n","    features = fe.compute_all_features(raw_df)\n","    print(f\"  Computed {len(FEATURE_COLUMNS)} features\")\n","    print(f\"  Feature groups: {list(FEATURE_GROUPS.keys())}\")\n","\n","    # Step 3: Compute targets\n","    print(\"\\n[Step 3] Computing targets...\")\n","    targets = fe.compute_targets(raw_df)\n","    target_cols = [c for c in targets.columns if c.startswith('target_')]\n","    print(f\"  Computed targets for horizons: {target_cols}\")\n","\n","    # Step 4: Save to parquet\n","    print(\"\\n[Step 4] Saving to parquet...\")\n","    with tempfile.TemporaryDirectory() as tmpdir:\n","        features_path = os.path.join(tmpdir, 'features.parquet')\n","        targets_path = os.path.join(tmpdir, 'targets.parquet')\n","\n","        features.to_parquet(features_path, compression='snappy')\n","        targets.to_parquet(targets_path, compression='snappy')\n","\n","        features_size = os.path.getsize(features_path) / (1024 * 1024)\n","        targets_size = os.path.getsize(targets_path) / (1024 * 1024)\n","\n","        print(f\"  Features: {features_size:.2f} MB\")\n","        print(f\"  Targets: {targets_size:.2f} MB\")\n","\n","        # Step 5: Verify roundtrip\n","        print(\"\\n[Step 5] Verifying roundtrip...\")\n","        loaded_features = pd.read_parquet(features_path)\n","        loaded_targets = pd.read_parquet(targets_path)\n","\n","        print(f\"  Features shape match: {features.shape == loaded_features.shape}\")\n","        print(f\"  Targets shape match: {targets.shape == loaded_targets.shape}\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"Phase 1 Demo Complete!\")\n","    print(\"\\nNext steps:\")\n","    print(\"  1. Run acquisition with real Databento API\")\n","    print(\"  2. Process full 15-year dataset\")\n","    print(\"  3. Save to Google Drive for Phase 2\")\n","\n","    return features, targets\n","\n","demo_features, demo_targets = run_phase1_demo()"]},{"cell_type":"markdown","metadata":{"id":"zZZVP6EFCRru"},"source":["## 10. Cleanup and Summary"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1765070484409,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"tqczyJOPCRrv","outputId":"c5cb79b4-70c8-498c-9976-096686996b71"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","DEV PHASE 1 TEST NOTEBOOK COMPLETE\n","======================================================================\n","\n","Summary:\n","- Verified FeatureEngineer initialization and configuration\n","- Verified 24 features across 6 groups per grok-scientific.md\n","- Tested all feature group computations:\n","  * F_P: Price dynamics (4 features)\n","  * F_V: Volume (3 features)\n","  * F_T: Trend (5 features) including VWAP with RTH reset\n","  * F_M: Momentum (6 features)\n","  * F_σ: Volatility (4 features)\n","  * F_VW + Temporal: Flow (2 features) including MFI and time_gap\n","- Tested target computation for 6 horizons\n","- Verified Parquet save/load roundtrip\n","- Validated Databento configuration\n","- Checked Phase 1 validation criteria\n","\n","Ready for Phase 2: Dataset and DataLoader implementation.\n","\n"]}],"source":["print(\"\\n\" + \"=\"*70)\n","print(\"DEV PHASE 1 TEST NOTEBOOK COMPLETE\")\n","print(\"=\"*70)\n","print(\"\"\"\n","Summary:\n","- Verified FeatureEngineer initialization and configuration\n","- Verified 24 features across 6 groups per grok-scientific.md\n","- Tested all feature group computations:\n","  * F_P: Price dynamics (4 features)\n","  * F_V: Volume (3 features)\n","  * F_T: Trend (5 features) including VWAP with RTH reset\n","  * F_M: Momentum (6 features)\n","  * F_σ: Volatility (4 features)\n","  * F_VW + Temporal: Flow (2 features) including MFI and time_gap\n","- Tested target computation for 6 horizons\n","- Verified Parquet save/load roundtrip\n","- Validated Databento configuration\n","- Checked Phase 1 validation criteria\n","\n","Ready for Phase 2: Dataset and DataLoader implementation.\n","\"\"\")"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":1051,"status":"ok","timestamp":1765070485475,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"8tPlmAFBENBC"},"outputs":[],"source":["# Cell: Install Dependencies for Data Acquisition\n","# ================================================\n","!pip install -q pandas numpy pyarrow scipy databento"]},{"cell_type":"code","source":["# Cell: Acquire Real Data from Databento\n","# =======================================\n","# WARNING: This will charge your Databento account (~$100-500)\n","# Run estimate_cost first to verify budget\n","\n","acquisition = NQDataAcquisition(\n","    api_key=DatabentoConfig.API_KEY,\n","    output_dir=str(DATA_ROOT + '/raw')\n",")\n","cost = acquisition.estimate_cost(\n","    DatabentoConfig.START_DATE,\n","    DatabentoConfig.END_DATE\n",")\n","print(f\"Estimated cost: ${cost:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lwAxl5f2U1Tn","executionInfo":{"status":"ok","timestamp":1765070489359,"user_tz":300,"elapsed":3843,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"}},"outputId":"13125b6c-c2be-4990-d6bf-59f7e48f6e8c"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Estimated cost: $19.11\n"]}]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":702871,"status":"ok","timestamp":1765071192240,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"oUeGKMRdDKxt","outputId":"c358d0c5-f366-4c0d-88be-bba1fd000d50"},"outputs":[{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/Colab Notebooks/Transformers/FP/src/data/acquisition.py:316: BentoWarning: The streaming request contained one or more days which have reduced quality: 2017-11-13 (degraded). See: https://databento.com/docs/api-reference-historical/metadata/metadata-get-dataset-condition\n","  data = self.client.timeseries.get_range(\n","/content/drive/MyDrive/Colab Notebooks/Transformers/FP/src/data/acquisition.py:316: BentoWarning: The streaming request contained one or more days which have reduced quality: 2018-10-21 (degraded). See: https://databento.com/docs/api-reference-historical/metadata/metadata-get-dataset-condition\n","  data = self.client.timeseries.get_range(\n","/content/drive/MyDrive/Colab Notebooks/Transformers/FP/src/data/acquisition.py:316: BentoWarning: The streaming request contained one or more days which have reduced quality: 2019-01-15 (degraded). See: https://databento.com/docs/api-reference-historical/metadata/metadata-get-dataset-condition\n","  data = self.client.timeseries.get_range(\n","/content/drive/MyDrive/Colab Notebooks/Transformers/FP/src/data/acquisition.py:316: BentoWarning: The streaming request contained one or more days which have reduced quality: 2019-02-22 (degraded), 2019-03-13 (degraded), 2019-03-26 (degraded). See: https://databento.com/docs/api-reference-historical/metadata/metadata-get-dataset-condition\n","  data = self.client.timeseries.get_range(\n","/content/drive/MyDrive/Colab Notebooks/Transformers/FP/src/data/acquisition.py:316: BentoWarning: The streaming request contained one or more days which have reduced quality: 2020-02-27 (degraded), 2020-02-28 (degraded). See: https://databento.com/docs/api-reference-historical/metadata/metadata-get-dataset-condition\n","  data = self.client.timeseries.get_range(\n","/content/drive/MyDrive/Colab Notebooks/Transformers/FP/src/data/acquisition.py:316: BentoWarning: The streaming request contained one or more days which have reduced quality: 2020-06-30 (degraded), 2020-07-01 (degraded). See: https://databento.com/docs/api-reference-historical/metadata/metadata-get-dataset-condition\n","  data = self.client.timeseries.get_range(\n","/content/drive/MyDrive/Colab Notebooks/Transformers/FP/src/data/acquisition.py:316: BentoWarning: The streaming request contained one or more days which have reduced quality: 2021-12-05 (degraded), 2022-01-02 (degraded). See: https://databento.com/docs/api-reference-historical/metadata/metadata-get-dataset-condition\n","  data = self.client.timeseries.get_range(\n","/content/drive/MyDrive/Colab Notebooks/Transformers/FP/src/data/acquisition.py:316: BentoWarning: The streaming request contained one or more days which have reduced quality: 2025-09-17 (degraded), 2025-09-24 (degraded), 2025-11-28 (degraded). See: https://databento.com/docs/api-reference-historical/metadata/metadata-get-dataset-condition\n","  data = self.client.timeseries.get_range(\n"]},{"output_type":"stream","name":"stdout","text":["Downloaded 5,236,084 bars\n","Date range: 2010-06-07 00:00:00+00:00 to 2025-12-03 23:59:00+00:00\n"]}],"source":["# Cell: Download Data (run after confirming cost)\n","# ===============================================\n","# Uncomment and run after verifying cost estimate\n","\n","raw_df = acquisition.download_range(\n","    start=DatabentoConfig.START_DATE,\n","    end=DatabentoConfig.END_DATE\n",")\n","# ... rest of cell\n","acquisition.save_parquet(raw_df, \"nq_ohlcv_1m_raw.parquet\")\n","print(f\"Downloaded {len(raw_df):,} bars\")\n","print(f\"Date range: {raw_df['timestamp'].min()} to {raw_df['timestamp'].max()}\")"]},{"cell_type":"code","source":["# # Cell: Recover Misplaced Data\n","# # ============================\n","# import shutil\n","# from pathlib import Path\n","\n","# # Define paths\n","# project_root = Path('/content/drive/MyDrive/Colab Notebooks/Transformers/FP')\n","# wrong_path = project_root / 'dataraw' / 'nq_ohlcv_1m_raw.parquet'\n","# correct_dir = project_root / 'data' / 'raw'\n","# correct_path = correct_dir / 'nq_ohlcv_1m_raw.parquet'\n","\n","# # Ensure correct directory exists\n","# correct_dir.mkdir(parents=True, exist_ok=True)\n","\n","# # Move file if in wrong location\n","# if wrong_path.exists():\n","#     print(f\"Moving {wrong_path.stat().st_size / (1024**2):.1f} MB from wrong location...\")\n","#     shutil.move(str(wrong_path), str(correct_path))\n","#     print(f\"✓ File moved to: {correct_path}\")\n","\n","#     # Cleanup\n","#     try:\n","#         wrong_path.parent.rmdir()\n","#         print(\"✓ Removed 'dataraw' directory\")\n","#     except OSError:\n","#         pass\n","# elif correct_path.exists():\n","#     print(f\"✓ File already in correct location: {correct_path}\")\n","# else:\n","#     print(\"⚠ File not found - may need to re-download\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oeJG6f-ImGMD","executionInfo":{"status":"ok","timestamp":1765073778546,"user_tz":300,"elapsed":30,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"}},"outputId":"906a968d-048b-4f05-a97a-d17cdb193a0d"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Moving 81.8 MB from wrong location...\n","✓ File moved to: /content/drive/MyDrive/Colab Notebooks/Transformers/FP/data/raw/nq_ohlcv_1m_raw.parquet\n","✓ Removed 'dataraw' directory\n"]}]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41157,"status":"ok","timestamp":1765073905962,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"},"user_tz":300},"id":"GN7TvGZSDNB9","outputId":"c2383b2c-1486-4331-9640-f6707739f941"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Features saved to: /content/drive/MyDrive/Colab Notebooks/Transformers/FP/data/processed/nq_features_v1.parquet\n","Targets saved to: /content/drive/MyDrive/Colab Notebooks/Transformers/FP/data/processed/nq_targets_v1.parquet\n","Stats saved to: /content/drive/MyDrive/Colab Notebooks/Transformers/FP/data/processed/feature_stats.json\n"]}],"source":["# Cell: Compute and Save Features\n","# ===============================\n","from src.data.features import compute_and_save_features\n","from pathlib import Path\n","\n","RAW_PATH = Path(PROJECT_ROOT) / 'data' / 'raw' / 'nq_ohlcv_1m_raw.parquet'\n","PROCESSED_DIR = Path(PROJECT_ROOT) / 'data' / 'processed'\n","PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Compute features and targets (stats saved to processed/ per function API)\n","features_path, targets_path, stats_path = compute_and_save_features(\n","    raw_data_path=str(RAW_PATH),\n","    output_dir=str(PROCESSED_DIR)\n",")\n","\n","print(f\"\\nFeatures saved to: {features_path}\")\n","print(f\"Targets saved to: {targets_path}\")\n","print(f\"Stats saved to: {stats_path}\")"]},{"cell_type":"code","source":["# Cell: Inspect Degraded Days Quality (Enhanced)\n","# ==============================================\n","\"\"\"\n","Comprehensive quality check for Databento-flagged degraded dates.\n","Combines completeness metrics with corruption detection.\n","\"\"\"\n","import pandas as pd\n","import numpy as np\n","from pathlib import Path\n","import json\n","\n","# Degraded dates from BentoWarnings\n","degraded_dates = [\n","    '2017-11-13', '2018-10-21', '2019-01-15', '2019-02-22', '2019-03-13', '2019-03-26',\n","    '2020-02-27', '2020-02-28', '2020-06-30', '2020-07-01', '2021-12-05', '2022-01-02',\n","    '2025-09-17', '2025-09-24', '2025-11-28'\n","]\n","\n","# Load raw data\n","raw_path = Path(PROJECT_ROOT) / 'data' / 'raw' / 'nq_ohlcv_1m_raw.parquet'\n","raw_df = pd.read_parquet(raw_path)\n","raw_df['timestamp'] = pd.to_datetime(raw_df['timestamp'])\n","raw_df['date'] = raw_df['timestamp'].dt.date\n","\n","print(\"=\" * 80)\n","print(\"DEGRADED DATES INSPECTION\")\n","print(\"=\" * 80)\n","\n","# Per-date analysis\n","stats = []\n","for date_str in degraded_dates:\n","    date = pd.to_datetime(date_str).date()\n","    day_data = raw_df[raw_df['date'] == date]\n","\n","    if len(day_data) == 0:\n","        stats.append({\n","            'date': date_str,\n","            'bars': 0,\n","            'completeness_%': 0,\n","            'zeros': 0,\n","            'max_return_%': 0,\n","            'status': 'NO_DATA'\n","        })\n","        continue\n","\n","    # Completeness (vs typical ~1400 bars/day)\n","    expected = 1400\n","    completeness = (len(day_data) / expected) * 100\n","\n","    # Corruption checks (Gemini)\n","    zeros = (day_data[['open', 'high', 'low', 'close']] == 0).sum().sum()\n","    returns = day_data['close'].pct_change().dropna()\n","    max_return = returns.abs().max() * 100 if len(returns) > 0 else 0\n","\n","    # Status classification\n","    if zeros > 0 or max_return > 10:\n","        status = 'CORRUPTED'\n","    elif completeness < 90:\n","        status = 'HIGH_IMPACT'\n","    elif completeness < 95:\n","        status = 'MINOR_GAPS'\n","    else:\n","        status = 'OK'\n","\n","    stats.append({\n","        'date': date_str,\n","        'bars': len(day_data),\n","        'completeness_%': completeness,\n","        'zeros': int(zeros),\n","        'max_return_%': max_return,\n","        'status': status\n","    })\n","\n","stats_df = pd.DataFrame(stats)\n","print(\"\\nPer-Date Summary:\")\n","print(stats_df.to_string(index=False))\n","\n","# Overall assessment\n","corrupted = stats_df[stats_df['status'] == 'CORRUPTED']\n","high_impact = stats_df[stats_df['status'] == 'HIGH_IMPACT']\n","print(f\"\\nSummary:\")\n","print(f\"  Corrupted (zeros or >10% jumps): {len(corrupted)}\")\n","print(f\"  High-impact (>10% missing bars): {len(high_impact)}\")\n","print(f\"  Total degraded bars: {stats_df['bars'].sum():,} of {len(raw_df):,} ({100*stats_df['bars'].sum()/len(raw_df):.3f}%)\")\n","\n","# Feature NaN impact (if features exist)\n","features_path = Path(PROJECT_ROOT) / 'data' / 'processed' / 'nq_features_v1.parquet'\n","if features_path.exists():\n","    from src.data.features import FEATURE_COLUMNS\n","    features_df = pd.read_parquet(features_path)\n","    features_df['date'] = pd.to_datetime(features_df['timestamp']).dt.date\n","\n","    degraded_dates_dt = [pd.to_datetime(d).date() for d in degraded_dates]\n","    degraded_features = features_df[features_df['date'].isin(degraded_dates_dt)]\n","\n","    nan_normal = features_df[FEATURE_COLUMNS].isna().mean().mean()\n","    nan_degraded = degraded_features[FEATURE_COLUMNS].isna().mean().mean()\n","    print(f\"\\nFeature NaN Rates:\")\n","    print(f\"  Overall: {nan_normal:.2%}\")\n","    print(f\"  Degraded days: {nan_degraded:.2%} (delta: +{nan_degraded - nan_normal:.2%})\")\n","\n","# Update stats.json with metadata\n","stats_path = Path(PROJECT_ROOT) / 'data' / 'processed' / 'feature_stats.json'\n","if stats_path.exists():\n","    with open(stats_path, 'r') as f:\n","        stats_json = json.load(f)\n","\n","    stats_json['degraded_days'] = {\n","        'dates': degraded_dates,\n","        'total_bars': int(stats_df['bars'].sum()),\n","        'pct_of_dataset': float(100 * stats_df['bars'].sum() / len(raw_df)),\n","        'corrupted_dates': corrupted['date'].tolist(),\n","        'high_impact_dates': high_impact['date'].tolist(),\n","        'avg_completeness': float(stats_df['completeness_%'].mean()),\n","    }\n","\n","    with open(stats_path, 'w') as f:\n","        json.dump(stats_json, f, indent=2)\n","\n","    print(f\"\\n✓ Updated {stats_path.name} with degraded_days metadata\")\n","\n","# Recommendations\n","if len(corrupted) > 0:\n","    print(\"\\n⚠ ACTION REQUIRED: Corrupted dates found\")\n","    print(\"  Consider filtering in Phase 2 Dataset or re-downloading\")\n","elif len(high_impact) > 0:\n","    print(\"\\n⚠ MONITOR: Some dates have significant gaps\")\n","    print(\"  Phase 2 masking will handle, but monitor training metrics\")\n","else:\n","    print(\"\\n✓ All degraded days usable - proceed to Phase 2\")"],"metadata":{"id":"JeP55UWHpDKn","executionInfo":{"status":"ok","timestamp":1765074560111,"user_tz":300,"elapsed":6289,"user":{"displayName":"Clemente Fortuna","userId":"08517700454351543390"}},"outputId":"d384ebce-ecd8-4b57-baf7-dd3ba5f3bb9d","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","DEGRADED DATES INSPECTION\n","================================================================================\n","\n","Per-Date Summary:\n","      date  bars  completeness_%  zeros  max_return_%      status\n","2017-11-13  1354       96.714286      0      0.087181          OK\n","2018-10-21   120        8.571429      0      0.098793 HIGH_IMPACT\n","2019-01-15  1365       97.500000      0      0.273920          OK\n","2019-02-22  1305       93.214286      0      0.176523  MINOR_GAPS\n","2019-03-13  1364       97.428571      0      0.177863          OK\n","2019-03-26  1365       97.500000      0      0.168413          OK\n","2020-02-27  1365       97.500000      0      0.537009          OK\n","2020-02-28   959       68.500000      0      0.710632 HIGH_IMPACT\n","2020-06-30   851       60.785714      0      0.244829 HIGH_IMPACT\n","2020-07-01  1365       97.500000      0      0.199277          OK\n","2021-12-05    60        4.285714      0      0.122611 HIGH_IMPACT\n","2022-01-02    60        4.285714      0      0.056449 HIGH_IMPACT\n","2025-09-17  1356       96.857143      0      0.184406          OK\n","2025-09-24  1380       98.571429      0      0.096124          OK\n","2025-11-28   448       32.000000      0      0.092613 HIGH_IMPACT\n","\n","Summary:\n","  Corrupted (zeros or >10% jumps): 0\n","  High-impact (>10% missing bars): 6\n","  Total degraded bars: 14,717 of 5,236,084 (0.281%)\n","\n","Feature NaN Rates:\n","  Overall: 0.00%\n","  Degraded days: 0.00% (delta: +-0.00%)\n","\n","✓ Updated feature_stats.json with degraded_days metadata\n","\n","⚠ MONITOR: Some dates have significant gaps\n","  Phase 2 masking will handle, but monitor training metrics\n"]}]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V6E1","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.0"}},"nbformat":4,"nbformat_minor":0}